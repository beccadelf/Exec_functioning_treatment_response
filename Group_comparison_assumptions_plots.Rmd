---
title: "Comparison_EF"
author: "Charlotte Meinke"
date: "2024-01-24"
output: 
  html_document:
      df_print: paged
      toc: yes
      toc_float: true
      toc_depth: 3
      number_sections: yes
      code_folding: hide
      fig_caption: yes
---

# Set-up
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(dplyr)
library(tidyr)
library(pander)
library(effsize)
library(pwr)
```

# Import data 
## Import task performance data
```{r}
NumberLetter_HC <- read.csv("Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Daten_Gruppenvergleich/NumberLetter_HC.csv")
NumberLetter_Patients_Post <- read.csv("Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Daten_Gruppenvergleich/NumberLetter_Patients_Post.csv")
NumberLetter_Patients_Pre <-  read.csv("Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Daten_Gruppenvergleich/NumberLetter_Patients_Pre.csv")

Stroop_HC <- read.csv("Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Daten_Gruppenvergleich/Stroop_HC.csv")
Stroop_Patients_Post <-  read.csv("Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Daten_Gruppenvergleich/Stroop_Patients_Post.csv")
Stroop_Patients_Pre <-  read.csv("Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Daten_Gruppenvergleich/Stroop_Patients_Pre.csv")

TwoBack_HC <- read.csv("Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Daten_Gruppenvergleich/TwoBack_HC.csv")
TwoBack_Patients_Post <-  read.csv("Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Daten_Gruppenvergleich/TwoBack_Patients_Post.csv")
TwoBack_Patients_Pre <-  read.csv("Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Daten_Gruppenvergleich/TwoBack_Patients_Pre.csv")
```

## Import 
```{r}
data_all <- haven::read_dta('Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/CognitiveControl_Treatment/Data_Kevin_28.07.23.dta')
colnames(data_all)[which(colnames(data_all) == "id")] <- "Subject"
```

# Comparison HC vs. Patients

## Prepare dataset
```{r}
# Merge patients and controls
## 1. Merge patients Pre (different tasks)
Patients_pre_2 <- merge(NumberLetter_Patients_Pre, Stroop_Patients_Pre, by = "Subject")
Patients_pre_3 <- merge(Patients_pre_2, TwoBack_Patients_Pre, by = "Subject")

## 2. Merge controls (different tasks)
Controls_2 <- merge(NumberLetter_HC, Stroop_HC, by = "Subject")
Controls_3 <- merge(Controls_2, TwoBack_HC, by = "Subject")

## 3. Merge Controls and patients
Patients_vs_HC <- rbind(Patients_pre_3, Controls_3)

## 4. Reduce dataset to BIS columns
BIS_columns <- colnames(Patients_vs_HC)[startsWith(colnames(Patients_vs_HC), "BIS")]
Patients_vs_HC_imp <- Patients_vs_HC[,c("Subject",BIS_columns,"Gruppe")]

## 5. Add better names 
Patients_vs_HC_imp <- Patients_vs_HC_imp %>%
  rename(NumberLetter_BIS_Repeat = BIS_Repeat,
         NumberLetter_BIS_Switch = BIS_Switch,
         Stroop_BIS_Congruent = BIS_Congruent,
         Stroop_BIS_Incongruent = BIS_Incongruent,
         TwoBack_BIS_Total = BIS_Total,
         TwoBack_BIS_Target = BIS_Target,
         TwoBack_BIS_Foil = BIS_Foil)

BIS_columns_renamed <- grep("BIS", colnames(Patients_vs_HC_imp), value = TRUE)

## 6. Add confounds (Alter, Geschlecht, Abschluss)
Patients_vs_HC_imp_conf <- merge(data_all[,c("Subject","Alter","Geschlecht","Abschluss")], Patients_vs_HC_imp, by = "Subject")
```
Data for `r nrow(Patients_vs_HC_imp[Patients_vs_HC_imp$Gruppe == 1,])` patients and `r nrow(Patients_vs_HC_imp[Patients_vs_HC_imp$Gruppe == 0,])` healthy controls were available.

## Testing assumption of independent sample t-test: normal distributions of the characteristic in both populations
#Implemented using a Kolmogorov-Smirnov test
```{r}
## Kolmogorov-Smirnov Test for Normality
ks_test_mult_cols <- function(df_basis, cols) {
  df <- data.frame(KS_statistic_group0 = numeric(length(cols)), p_value_group0 = numeric(length(cols)),
                   KS_statistic_group1 = numeric(length(cols)), p_value_group1 = numeric(length(cols)))
  rownames(df) <- cols
  for (col in cols) {
    group0 <- df_basis[df_basis[["Gruppe"]] == 0, col]
    group1 <- df_basis[df_basis[["Gruppe"]] == 1, col]
    
    # Test: comparing group data to a normal distribution
    ks_test_group0 <- ks.test(group0, "pnorm", mean(group0), sd(group0))
    ks_test_group1 <- ks.test(group1, "pnorm", mean(group1), sd(group1))
    
    # Store the results
    df[col, "KS_statistic_group0"] <- round(ks_test_group0$statistic, 3)
    df[col, "p_value_group0"] <- round(ks_test_group0$p.value, 3)
    df[col, "KS_statistic_group1"] <- round(ks_test_group1$statistic, 3)
    df[col, "p_value_group1"] <- round(ks_test_group1$p.value, 3)
  }
  return(df)
}

# Apply K-S test function to data
ks_test_table <- ks_test_mult_cols(df_basis = Patients_vs_HC_imp, cols = BIS_columns_renamed)
pander(ks_test_table, style = "rmarkdown", fontsize = "tiny")

```
The Kolmogoroff-Smirnov tests show significant deviations from normal distribution for the Number-Letter and Stroop tasks in the healthy controls (alpha=0.05). 
However, with Bonferroni correction (alpha=0.003), only the Stroop test would violate the assumption.

## Calculate Welch t-test  
```{r}
t_test_mult_cols <- function(df_basis, cols) {
  df <- data.frame(t_statistic = numeric(length(cols)), p_value = numeric(length(cols)),
                   group_mean_Patients = numeric(length(cols)), sd_Patients = numeric(length(cols)),
                   group_mean_HC = numeric(length(cols)), sd_HC = numeric(length(cols)),
                   cohen_d = numeric(length(cols)))
  rownames(df) <- cols
  for (col in cols) {
    # Using the non-formula interface
    group0 <- df_basis[df_basis[["Gruppe"]] == 0, col]
    group1 <- df_basis[df_basis[["Gruppe"]] == 1, col]
    results <- t.test(group0, group1, paired = FALSE, var.equal = FALSE)
    
    # Calculate Cohen's d using the cohen.d function (effect size)
    cohen_d_result <- cohen.d(group0, group1, hedges.correction = FALSE)
    cohen_d <- cohen_d_result$estimate
    
    # Calculate power using pwr.t.test
    n0 <- length(group0)
    n1 <- length (group1)
    power_result <- pwr.t.test(d = cohen_d, n = min(n0, n1), sig.level = 0.05, type = "two.sample", alternative = "greater")
                                                                        #0.007? (Bonferroni)                       #two.sided?
    power <- power_result$power
    
    # Store the results
    df[col, "t_statistic"] <- round(results$statistic, 2)
    df[col, "p_value"] <- round(results$p.value, 2)
    df[col, "group_mean_Patients"] <- round(mean(group0), 2)
    df[col, "sd_Patients"] <- round(sd(group0), 2)
    df[col, "group_mean_HC"] <- round(mean(group1), 2)
    df[col, "sd_HC"] <- round(sd(group1), 2)
    df[col, "cohen_d"] <- round(cohen_d, 2)
    df[col, "power"] <- round(power, 2)
  }
  return(df)
}

t_test_table <- t_test_mult_cols(df_basis = Patients_vs_HC_imp, cols = BIS_columns_renamed)
pander(t_test_table, style = "rmarkdown", fontsize = "tiny")
```
Patients performed better than healthy controls, especially in the Stroop and the NumberLetterTask. However, please note that we have not tested for baseline differences (e.g., education, age...). This is done in the following step


## Control Welch-test for covariates age, sex, and education
```{r}
library(gtsummary)
table1 <- 
  Patients_vs_HC_imp_conf %>%
  tbl_summary(include = c(Alter, Geschlecht, Abschluss), by = Gruppe)

table1
```


```{r}
ANCOVA_mult_cols <- function(df_basis, cols, covariates = NULL){
  # Create a overview of ANCOVA results for several columns in a dataframe
  df <- data.frame(Gruppe_p_value = numeric(length(cols)))
  rownames(df) <- cols
  for (col in cols){
    # Run ANCOVA
    formula <- paste(col, " ~ Gruppe", ifelse(length(covariates) > 0, paste(" + ", paste(covariates, collapse = " + ")), ""))
    anova_result <- aov(as.formula(formula), data = df_basis)
    coefficients <- coef(anova_result)
    summary_anova <- summary(anova_result)
    print(summary_anova)
    
    # Prepare nice table to summarize the results
    df[col, "Gruppe_p_value"] <- round(summary_anova[[1]]$"Pr(>F)"[1],2)
    df[col, "Gruppe_corrected_difference"] <- round(coefficients[2],2)
    df[col, "Alter_p_value"] <- round(summary_anova[[1]]$"Pr(>F)"[2],2)
    df[col, "Geschlecht_p_value"] <- round(summary_anova[[1]]$"Pr(>F)"[3],2)
    df[col, "Abschluss_p_value"] <- round(summary_anova[[1]]$"Pr(>F)"[4],2)
  }
  return(df)
}

table_ANCOVA <- ANCOVA_mult_cols(df_basis = Patients_vs_HC_imp_conf, cols = BIS_columns_renamed, covariates = c("Alter","Geschlecht","Abschluss"))
pander(table_ANCOVA, style = "rmarkdown", fontsize = "tiny")
```
3 observations with missings in the covariates are automatically deleted.
In the Numberletter task, the difference between patients and healthy controls remained when controlling for covariates. However, also education had a main effect on performance.
In the Stroop task, the difference between patients and healthy controls also remained when contrlloing for covariates. Here, also the gender and education had a main effect on performance.
There was no significant effect between patients and controls in the TwoBackTask - also not when controlling for covariates. The task types Total and Foil might mainly depend on the age.

# Comparison pre vs.post
```{r}
## Merge patients pre
Patients_pre_2 <- merge(NumberLetter_Patients_Pre, Stroop_Patients_Pre, by = "Subject")
Patients_pre_3 <- merge(Patients_pre_2, TwoBack_Patients_Pre, by = "Subject")
Patients_pre_3$time <- "pre"

## Merge patients Post
Patients_post_2 <- merge(NumberLetter_Patients_Post, Stroop_Patients_Post, by = "Subject")
Patients_post_3 <- merge(Patients_post_2, TwoBack_Patients_Post, by = "Subject")
Patients_post_3$time <- "post"

# Combine data
Patients_pre_3$Subject <- Patients_pre_3$Subject + 600 # This was the ID given 
Patients_pre_vs_post <- rbind(Patients_post_3, Patients_pre_3)
# Remove data if subjects had only pre-values
subject_counts <- table(Patients_pre_vs_post$Subject)
multiple_rows_subjects <- names(subject_counts)[subject_counts > 1]
Patients_pre_vs_post_clean <- Patients_pre_vs_post[Patients_pre_vs_post$Subject %in% multiple_rows_subjects, ]

# Reduce to BIS
BIS_columns <- colnames(Patients_pre_vs_post_clean)[startsWith(colnames(Patients_pre_vs_post_clean), "BIS")]
Patients_pre_vs_post_imp <- Patients_pre_vs_post_clean[,c("Subject",BIS_columns,"time")]

## Add better names 
Patients_pre_vs_post_imp <- Patients_pre_vs_post_imp %>%
  rename(NumberLetter_BIS_Repeat = BIS_Repeat,
         NumberLetter_BIS_Switch = BIS_Switch,
         Stroop_BIS_Congruent = BIS_Congruent,
         Stroop_BIS_Incongruent = BIS_Incongruent,
         TwoBack_BIS_Total = BIS_Total,
         TwoBack_BIS_Target = BIS_Target,
         TwoBack_BIS_Foil = BIS_Foil)
BIS_columns_renamed <- grep("BIS", colnames(Patients_pre_vs_post_imp), value = TRUE)
```
Pre and post measures were available for `r nrow(Patients_pre_vs_post_imp) / 2` patients.

## Testing assumptions of dependent sample t-test
#1. Normal distribution of difference values: implemented using Kolmogoroff-Smirnov test to difference values (d_i=Post_i-Pre_i)
```{r}
## Kolmogorov-Smirnov Test for Normality of Difference Values
ks_test_diff_values <- function(df_basis, cols) {
  df <- data.frame(KS_statistic = numeric(length(cols)), p_value = numeric(length(cols)))
  rownames(df) <- cols
  for (col in cols) {
    # Calculate difference values (Post - Pre)
    diff_values <- df_basis[df_basis[["time"]] == "post", col] - df_basis[df_basis[["time"]] == "pre", col]
    # Perform Kolmogorov-Smirnov test comparing difference values to a normal distribution
    ks_test_diff <- ks.test(diff_values, "pnorm", mean(diff_values), sd(diff_values))
    
    # Store the results
    df[col, "KS_statistic"] <- round(ks_test_diff$statistic, 3)
    df[col, "p_value"] <- round(ks_test_diff$p.value, 3)
  }
  return(df)
}

# Apply K-S test function to the difference values in data
ks_test_diff_table <- ks_test_diff_values(df_basis = Patients_pre_vs_post_imp, cols = BIS_columns_renamed)
pander(ks_test_diff_table, style = "rmarkdown", fontsize = "tiny")
```
The assumption of normal distribution is violated for all but the TwoBack task for alpha=0.05. 
However, if we apply Bonferroni correction (alpha=0.007) only the Number-Letter Repeat and Stroop tests would violate the assumption.

```{r}
#Helper function to avoid redundancy: Get pre and post data in one place
get_pre_post_data <- function(df_basis, col) {
  pre_data <- df_basis[df_basis[["time"]] == "pre", col]
  post_data <- df_basis[df_basis[["time"]] == "post", col]
  return(list(pre = pre_data, post = post_data))
}
```

#2. Positive correlation of measurement series: 
```{r}
## Calculate Raw Pearson Correlation, then test Significance
calculate_correlations_and_significance <- function(df_basis, cols) {
  df <- data.frame(Correlation = numeric(length(cols)), t_statistic = numeric(length(cols)), 
                   p_value = numeric(length(cols)))
  rownames(df) <- cols
  for (col in cols) {
    # Get pre and post data using the helper function
    data <- get_pre_post_data(df_basis, col)
    pre_data <- data$pre
    post_data <- data$post
    
    # Calculate Pearson correlation
    correlation <- cor(pre_data, post_data)
    
    # Calculate the t-statistic for the correlation
    n <- length(pre_data)
    t_statistic <- correlation * sqrt((n - 2) / (1 - correlation^2))
    
    # Calculate the p-value for a one-tailed test (H_0: r ≤ 0)
    p_value <- pt(t_statistic, df = n - 2, lower.tail = FALSE)
    
    # Store the results
    df[col, "Correlation"] <- round(correlation, 3)
    df[col, "t_statistic"] <- round(t_statistic, 3)
    df[col, "p_value"] <- round(p_value, 3)
  }
  return(df)
}


# Apply correlation and significance test to data
correlation_significance_table <- calculate_correlations_and_significance(df_basis = Patients_pre_vs_post_imp, cols = BIS_columns_renamed)
pander(correlation_significance_table, style = "rmarkdown", fontsize = "tiny")
```
For all tasks, the correlations of the measurement series are significantly positive. Thus, the assumption is met for all tasks. 

## Calculate Welch t-test
```{r}
paired_t_test_mult_cols <- function(df_basis, cols) {
  df <- data.frame(t_statistic = numeric(length(cols)), p_value = numeric(length(cols)),
                   group_mean_pre = numeric(length(cols)), group_mean_post = numeric(length(cols)),
                   cohen_d = numeric(length(cols)))
  rownames(df) <- cols
  for (col in cols) {
    # Get pre and post data using get_pre_post_data helper function
    data <- get_pre_post_data(df_basis, col)
    pre_data <- data$pre
    post_data <- data$post
    
    # non-formula interface as before
    results <- t.test(pre_data, post_data, paired = TRUE, var.equal = FALSE)
    
    # Calculate Cohen's d using the cohen.d function for paired samples (effect size)
    cohen_d_result <- cohen.d(post_data, pre_data, paired = TRUE)
    cohen_d <- cohen_d_result$estimate
    
    # Calculate power using pwr.t.test
    n <- length(pre_data)
    power_result <- pwr.t.test(d = cohen_d, n = n, sig.level = 0.05, type = "paired", alternative = "greater")
                                                              #0.007? (Bonferroni)                  #two.sided?
    power <- power_result$power
    
    # Store the results
    df[col, "t_statistic"] <- round(results$statistic, 2)
    df[col, "p_value"] <- round(results$p.value, 2)
    df[col, "group_mean_pre"] <- round(mean(pre_data), 2)
    df[col, "sd_pre"] <- round(sd(pre_data), 2)
    df[col, "group_mean_post"] <- round(mean(post_data), 2)
    df[col, "sd_post"] <- round(sd(post_data), 2)
    df[col, "cohen_d"] <- round(cohen_d, 2)
    df[col, "power"] <- round(power, 2)
  }
  return(df)
}

t_test_table_pre_post <- paired_t_test_mult_cols(df_basis = Patients_pre_vs_post_imp, cols = BIS_columns_renamed)
pander(t_test_table_pre_post)
```

Patients performed better in all measurements of executive functioning after the exposure session. This might be due to a practice effect.

# Plotting

## Comparison HC vs. patients (pre)
```{r}
# Reshape data from wide to long format
Patients_vs_HC_long <- Patients_vs_HC_imp %>%
  pivot_longer(cols = all_of(BIS_columns_renamed),
               names_to = "Condition",
               values_to = "BIS_Score")

# Add new task variable
Patients_vs_HC_long <- Patients_vs_HC_long %>%
  mutate(Task = case_when(
    grepl("NumberLetter", Condition) ~ "NumberLetter",
    grepl("Stroop", Condition) ~ "Stroop",
    grepl("TwoBack", Condition) ~ "TwoBack"
  ))

# Create boxplots
boxplots_Patients_HC <- ggplot(Patients_vs_HC_long, aes(x = Condition, y = BIS_Score, fill = factor(Gruppe))) +
  geom_boxplot(outlier.shape = NA, alpha = 0.6, position = position_dodge(width = 0.8)) +
  geom_jitter(aes(color = factor(Gruppe)), 
              position = position_dodge(width = 0.8),
              size = 0.5, alpha = 0.7) + 
  facet_grid(rows = vars(Task), scales = "free_x") +
  labs(title = "Boxplots of Task Condition by Group",
       x = "Condition",
       y = "BIS-Score",
       fill = "Group")
```

## Comparison patients pre vs. post
```{r}
# Reshape data from wide to long format
Patients_pre_vs_post_long <- Patients_pre_vs_post_imp %>%
  pivot_longer(cols = all_of(BIS_columns_renamed),
               names_to = "Condition",
               values_to = "BIS_Score")

# Add new task variable
Patients_pre_vs_post_long <- Patients_pre_vs_post_long %>%
  mutate(Task = case_when(
    grepl("NumberLetter", Condition) ~ "NumberLetter",
    grepl("Stroop", Condition) ~ "Stroop",
    grepl("TwoBack", Condition) ~ "TwoBack"
  ))
```

