## Step 2: Remove outlier
filter(RT > 150)
# STEP 1.2.: Compute mean RT overall and per condition
overall_RT_mean <- mean(data_RT_clean$RT)
RT_means <- data_RT_clean %>%
group_by(Condition) %>%
summarize_at(vars(RT), mean)
## Transform data from LONG to WIDE format
wideData_RT <- RT_means %>%
pivot_wider(names_from = Condition, values_from = RT)
# STEP 2: Compute proportion correct overall and per condition
overall_PC <- mean(data_red$Accuracy)
PC <- data_red %>%
group_by(Condition) %>%
summarize_at(vars(Accuracy), mean)
## TODO: Convert to percentages?
## Transform data from LONG to WIDE format
wideData_PC <- PC %>%
pivot_wider(names_from = Condition, values_from = Accuracy)
# STEP 3: Merging the two wide dataframe
## Update column names to include the variable identity
colnames(wideData_RT) <- paste(colnames(wideData_RT),"RT", sep="_")
colnames(wideData_PC) <- paste(colnames(wideData_PC),"PC", sep="_")
## Merge dataframes
wideData_merged <- cbind(wideData_RT, wideData_PC)
# STEP 4: Adding extra relevant info
## Add subject ID, overall mean RT and overall PC
wideData_merged$Subject <- subject
wideData_merged$Overall_RT <- overall_RT_mean
wideData_merged$Overall_PC <- overall_PC
## Store the current processed data into holder as a new row
AllData <- rbind(AllData, wideData_merged)
}
return(AllData)
}
# Function 4: calculate mean and SD of RT and PC of healthy subjects
# mean_sd_HC <- function(data_HC){
#   # Calculate mean and sd of RT and PC across all healthy subjects and conditions
#   meanRT_HC <- mean(data_HC$Overall_RT)
#   sdRT_HC <- sd(data_HC$Overall_RT)
#   meanPC_HC <- mean(data_HC$Overall_PC)
#   sdPC_HC <- sd(data_HC$Overall_PC)
#   return(meanRT_HC, sdRT_HC, meanPC_HC, sdPC_HC) # TODO: have to be stored in a list
# }
basic_path = "Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Rohdaten/Task_battery/Task_battery"
# Load data
data_all <- read_dta('Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Rohdaten/CRC_C5_Hilbert/CRC_C5_Hilbert/Data_Kevin_28.07.23.dta')
data_tasks_old <- read_dta('Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Rohdaten/CRC_C5_Hilbert/CRC_C5_Hilbert/TaskBattery.dta')
data_all_red <- data_all %>%
rename(Subject = id) %>%
select(Subject, Gruppe, T1_BAT_FAS_score, T3_BAT_FAS_score)
# Rename stid for later merge
data_tasks_old <- data_tasks_old %>%
rename(Subject = stid)
files <- list.files(basic_path)
sub_first <- gsub("SFB_C5_","",files)
sub_IDs <- sapply(strsplit(sub_first, "_"), function(x) x[1])
subjects <- unique(sub_IDs)
# Delete alt and "" from subjects
subjects <- subjects[subjects != "alt"]
subjects <- subjects[subjects != ""]
AllData_NumbLet <- preprocess_RT_PC(task = "NumberLetter", subjects = subjects)
AllData_Stroop <- preprocess_RT_PC(task = "Stroop", subjects = subjects)
AllData_TwoBack <- preprocess_RT_PC(task = "TwoBack", subjects = subjects)
# Initialize empty holder dataframe
AllData_SST <- data.frame()
for (subject in subjects) {
data_SST <- df_from_matlab(task_name = "StopSignal", subject = subject)
# Reduce to only relevant variables
data_SST_red <- data_SST %>%
select(Condition, RT, Accuracy, `Stop-signal delay`)
# Recode condition: Go -> 0, Stop -> 1
data_SST_red$Condition <- ifelse(data_SST_red$Condition == "Go", 0, 1)
# Convert all columns to numeric
data_SST_red[] <- lapply(data_SST_red, as.numeric)
# Calculate SSRT
SSRT_value <- integration_adaptiveSSD(data_SST_red, stop_col = "Condition", rt_col = "RT",
acc_col = "Accuracy", ssd_col = "Stop-signal delay")
# Append the result to SSRT_all
AllData_SST <- rbind(AllData_SST, data.frame(Subject = subject, SSRT = SSRT_value))
}
# Align data types
data_all_red$Subject <- as.character(data_all_red$Subject)
merged_data <- AllData_NumbLet %>%
# 1. Merge all task dataframes
left_join(AllData_Stroop, by = "Subject") %>%
left_join(AllData_TwoBack, by = "Subject") %>%
left_join(AllData_SST, by = "Subject") %>%
# 2. Add data_all_red
left_join(data_all_red, by = "Subject")
# Change variable names
merged_data <- merged_data %>%
rename(NumbLet_Average_RT = Overall_RT.x,
NumbLet_Average_PC = Overall_PC.x,
Stroop_Average_RT = Overall_RT.y,
Stroop_Average_PC = Overall_PC.y,
TwoBack_Average_RT = Overall_RT,
TwoBack_Average_PC = Overall_PC)
# Assign post IDs (Gruppe = 2)
merged_data <- merged_data %>%
mutate(Subject = as.numeric(Subject),
Gruppe = ifelse(Subject >= 216601 & Subject <= 216760, 2, Gruppe))
# 1. Remove subjects with missing group information
merged_data_excl1 <- merged_data %>%
filter(!is.na(Gruppe))
excl_group <- anti_join(merged_data, merged_data_excl1, by = "Subject")
# 2. Remove patients with missing FAS_T1 and/or FAS_T3
merged_data_clean <- merged_data_excl1 %>%
filter(Gruppe == 0 | Gruppe == 2 | (Gruppe == 1 & !is.na(T1_BAT_FAS_score) & !is.na(T3_BAT_FAS_score)))
excl_criterion <- anti_join(merged_data_excl1, merged_data_clean, by = "Subject")
## Step 1: Calculate mean and SD for RT and PC across all healthy subjects and all conditions
NumbLet_mean_sd_HC <- merged_data_clean %>%
filter(Gruppe == 0) %>%
select(NumbLet_Average_RT, NumbLet_Average_PC) %>%
summarise(meanRT = mean(NumbLet_Average_RT),
meanPC = mean(NumbLet_Average_PC),
sdRT = sd(NumbLet_Average_RT),
sdPC = sd(NumbLet_Average_PC))
## Step 2: Standardize RT and PC for each condition
merged_data_clean <- merged_data_clean %>%
mutate(Z_Repeat_RT = (Repeat_RT - NumbLet_mean_sd_HC$meanRT) / NumbLet_mean_sd_HC$sdRT,
Z_Switch_RT = (Switch_RT - NumbLet_mean_sd_HC$meanRT) / NumbLet_mean_sd_HC$sdRT,
Z_Repeat_PC = (Repeat_PC - NumbLet_mean_sd_HC$meanPC) / NumbLet_mean_sd_HC$sdPC,
Z_Switch_PC = (Switch_PC - NumbLet_mean_sd_HC$meanPC) / NumbLet_mean_sd_HC$sdPC)
# Step 3: Calculate BIS(Repeat), BIS(Switch) and Difference Score
merged_data_clean <- merged_data_clean %>%
mutate(NumberLetter_BIS_Repeat = Z_Repeat_PC - Z_Repeat_RT,
NumberLetter_BIS_Switch = Z_Switch_PC - Z_Switch_RT) %>%
mutate(NumberLetter_BIS_Diff_Score = NumberLetter_BIS_Switch - NumberLetter_BIS_Repeat)
## Step 1: Calculate mean and SD for RT and PC across all healthy subjects and all conditions
Stroop_mean_sd_HC <- merged_data_clean %>%
filter(Gruppe == 0) %>%
select(Stroop_Average_RT, Stroop_Average_PC) %>%
summarise(meanRT = mean(Stroop_Average_RT),
meanPC = mean(Stroop_Average_PC),
sdRT = sd(Stroop_Average_RT),
sdPC = sd(Stroop_Average_PC))
## Step 2: Standardize RT and PC for each condition
merged_data_clean <- merged_data_clean %>%
mutate(Z_Congruent_RT = (Congruent_RT - Stroop_mean_sd_HC$meanRT) / Stroop_mean_sd_HC$sdRT,
Z_Incongruent_RT = (Incongruent_RT - Stroop_mean_sd_HC$meanRT) / Stroop_mean_sd_HC$sdRT,
Z_Congruent_PC = (Congruent_PC - Stroop_mean_sd_HC$meanPC) / Stroop_mean_sd_HC$sdPC,
Z_Incongruent_PC = (Incongruent_PC - Stroop_mean_sd_HC$meanPC) / Stroop_mean_sd_HC$sdPC)
# Step 3: Calculate BIS(Congruent), BIS(Incongruent) and Difference Score
merged_data_clean <- merged_data_clean %>%
mutate(Stroop_BIS_Congruent = Z_Congruent_PC - Z_Congruent_RT,
Stroop_BIS_Incongruent = Z_Incongruent_PC - Z_Incongruent_RT) %>%
mutate(Stroop_BIS_Diff_Score = Stroop_BIS_Incongruent - Stroop_BIS_Congruent)
## Step 1: Calculate mean and SD for RT and PC across all healthy subjects and all conditions
TwoBack_mean_sd_HC <- merged_data_clean %>%
filter(Gruppe == 0) %>%
select(TwoBack_Average_RT, TwoBack_Average_PC) %>%
summarise(meanRT = mean(TwoBack_Average_RT),
meanPC = mean(TwoBack_Average_PC),
sdRT = sd(TwoBack_Average_RT),
sdPC = sd(TwoBack_Average_PC))
## Step 2: Standardize RT and PC for each condition
merged_data_clean <- merged_data_clean %>%
mutate(Z_Total_RT = (TwoBack_Average_RT - TwoBack_mean_sd_HC$meanRT) / TwoBack_mean_sd_HC$sdRT,
Z_Target_RT = (Target_RT - TwoBack_mean_sd_HC$meanRT) / TwoBack_mean_sd_HC$sdRT,
Z_Foil_RT = (Foil_RT - TwoBack_mean_sd_HC$meanRT) / TwoBack_mean_sd_HC$sdRT,
Z_Total_PC = (TwoBack_Average_PC - TwoBack_mean_sd_HC$meanPC) / TwoBack_mean_sd_HC$sdPC,
Z_Target_PC = (Target_PC - TwoBack_mean_sd_HC$meanPC) / TwoBack_mean_sd_HC$sdPC,
Z_Foil_PC = (Foil_PC - TwoBack_mean_sd_HC$meanPC) / TwoBack_mean_sd_HC$sdPC)
# Calculate BIS(Target), BIS(Total) and BIS_Foil
merged_data_clean <- merged_data_clean %>%
mutate(TwoBack_BIS_Total = Z_Total_PC - Z_Total_RT,
TwoBack_BIS_Target = Z_Target_PC - Z_Target_RT,
TwoBack_BIS_Foil = Z_Foil_PC - Z_Foil_RT)
split_df <- split(merged_data_clean, merged_data_clean$Gruppe)
data_HC <- split_df$"0"
data_Pat_pre <- split_df$"1"
data_Pat_post <- split_df$"2"
file_path <- "Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Daten_Gruppenvergleich/With_wrong_responses/"
# Write data to CSV using the function
write.csv(data_HC, paste0(file_path, "Data_HC.csv"), row.names = FALSE)
write.csv(data_Pat_pre, paste0(file_path, "Data_Patients_Pre.csv"), row.names = FALSE)
write.csv(data_Pat_post, paste0(file_path, "Data_Patients_Post.csv"), row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(tidyr)
library(pander)
library(effsize)
library(pwr)
library(gtsummary)
data_HC <- read.csv("Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Daten_Gruppenvergleich/With_wrong_responses/Data_HC.csv")
data_Pat_pre <- read.csv("Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Daten_Gruppenvergleich/With_wrong_responses/Data_Patients_Pre.csv")
data_Pat_post <- read.csv("Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Daten_Gruppenvergleich/With_wrong_responses/Data_Patients_Post.csv")
data_all <- haven::read_dta('Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/CognitiveControl_Treatment/Data_Kevin_28.07.23.dta')
colnames(data_all)[which(colnames(data_all) == "id")] <- "Subject"
Patients_vs_HC <- rbind(data_Pat_pre, data_HC)
BIS_columns <- colnames(Patients_vs_HC)[grep("BIS", colnames(Patients_vs_HC))]
BIS_columns
Patients_vs_HC_imp <- Patients_vs_HC[,c("Subject","Gruppe",BIS_columns,"SSRT")]
View(Patients_vs_HC_imp)
Patients_vs_HC_imp_conf <- merge(data_all[,c("Subject","Alter","Geschlecht","Abschluss")], Patients_vs_HC_imp, by = "Subject")
imp_columns <- c(BIS_columns, "SSRT")
t_test_mult_cols <- function(df_basis, cols) {
df <- data.frame(t_statistic = numeric(length(cols)), p_value = numeric(length(cols)),
group_mean_Patients = numeric(length(cols)), sd_Patients = numeric(length(cols)),
group_mean_HC = numeric(length(cols)), sd_HC = numeric(length(cols)),
cohen_d = numeric(length(cols)))
rownames(df) <- cols
for (col in cols) {
# Using the non-formula interface
group0 <- df_basis[df_basis[["Gruppe"]] == 0, col]
group1 <- df_basis[df_basis[["Gruppe"]] == 1, col]
results <- t.test(group0, group1, paired = FALSE, var.equal = FALSE)
#Alternativ using formula method:
#results <- t.test(df_basis[[col]] ~ df_basis[["Gruppe"]], paired = FALSE, var.equal = FALSE)
# Calculate Cohen's d using the cohen.d function (effect size)
cohen_d_result <- cohen.d(group0, group1, hedges.correction = FALSE)
cohen_d <- cohen_d_result$estimate
# Calculate power using pwr.t.test (Bonferroni=0.007?; two-sided?)
n0 <- length(group0)
n1 <- length (group1)
power_result <- pwr.t.test(d = cohen_d, n = min(n0, n1), sig.level = 0.05, type = "two.sample", alternative = "greater")
power <- power_result$power
# Store the results
df[col, "t_statistic"] <- round(results$statistic, 2)
df[col, "p_value"] <- round(results$p.value, 2)
df[col, "group_mean_Patients"] <- round(mean(group1), 2)
df[col, "sd_Patients"] <- round(sd(group0), 2)
df[col, "group_mean_HC"] <- round(mean(group0), 2)
df[col, "sd_HC"] <- round(sd(group1), 2)
df[col, "cohen_d"] <- round(cohen_d, 2)
df[col, "power"] <- round(power, 2)
}
return(df)
}
t_test_table <- t_test_mult_cols(df_basis = Patients_vs_HC_imp, cols = imp_columns)
pander(t_test_table, style = "rmarkdown", fontsize = "tiny")
is.na(Patients_vs_HC_imp$SSRT)
t_test_mult_cols <- function(df_basis, cols) {
df <- data.frame(t_statistic = numeric(length(cols)), p_value = numeric(length(cols)),
group_mean_Patients = numeric(length(cols)), sd_Patients = numeric(length(cols)),
group_mean_HC = numeric(length(cols)), sd_HC = numeric(length(cols)),
cohen_d = numeric(length(cols)))
rownames(df) <- cols
for (col in cols) {
# Using the non-formula interface
group0 <- na.omit(df_basis[df_basis[["Gruppe"]] == 0, col])
group1 <- na.omit(df_basis[df_basis[["Gruppe"]] == 1, col])
results <- t.test(group0, group1, paired = FALSE, var.equal = FALSE)
#Alternativ using formula method:
#results <- t.test(df_basis[[col]] ~ df_basis[["Gruppe"]], paired = FALSE, var.equal = FALSE)
# Calculate Cohen's d using the cohen.d function (effect size)
cohen_d_result <- cohen.d(group0, group1, hedges.correction = FALSE)
cohen_d <- cohen_d_result$estimate
# Calculate power using pwr.t.test (Bonferroni=0.007?; two-sided?)
n0 <- length(group0)
n1 <- length (group1)
power_result <- pwr.t.test(d = cohen_d, n = min(n0, n1), sig.level = 0.05, type = "two.sample", alternative = "greater")
power <- power_result$power
# Store the results
df[col, "t_statistic"] <- round(results$statistic, 2)
df[col, "p_value"] <- round(results$p.value, 2)
df[col, "group_mean_Patients"] <- round(mean(group1), 2)
df[col, "sd_Patients"] <- round(sd(group0), 2)
df[col, "group_mean_HC"] <- round(mean(group0), 2)
df[col, "sd_HC"] <- round(sd(group1), 2)
df[col, "cohen_d"] <- round(cohen_d, 2)
df[col, "power"] <- round(power, 2)
}
return(df)
}
t_test_table <- t_test_mult_cols(df_basis = Patients_vs_HC_imp, cols = imp_columns)
pander(t_test_table, style = "rmarkdown", fontsize = "tiny")
#Descriptive statistics
table1 <-
Patients_vs_HC_imp_conf %>%
tbl_summary(include = c(Alter, Geschlecht, Abschluss), by = Gruppe)
pander(as.data.frame(table1))
#ANCOVA
ANCOVA_mult_cols <- function(df_basis, cols, covariates = NULL){
# Create a overview of ANCOVA results for several columns in a dataframe
df <- data.frame(Gruppe_p_value = numeric(length(cols)))
rownames(df) <- cols
for (col in cols){
# Run ANCOVA
formula <- paste(col, " ~ Gruppe", ifelse(length(covariates) > 0, paste(" + ", paste(covariates, collapse = " + ")), ""))
anova_result <- aov(as.formula(formula), data = df_basis)
coefficients <- coef(anova_result)
summary_anova <- summary(anova_result)
#print(summary_anova)
# Prepare nice table to summarize the results
df[col, "Gruppe_p_value"] <- round(summary_anova[[1]]$"Pr(>F)"[1],2)
df[col, "Gruppe_corrected_difference"] <- round(coefficients[2],2)
df[col, "Alter_p_value"] <- round(summary_anova[[1]]$"Pr(>F)"[2],2)
df[col, "Geschlecht_p_value"] <- round(summary_anova[[1]]$"Pr(>F)"[3],2)
df[col, "Abschluss_p_value"] <- round(summary_anova[[1]]$"Pr(>F)"[4],2)
}
return(df)
}
table_ANCOVA <- ANCOVA_mult_cols(df_basis = Patients_vs_HC_imp_conf, cols = imp_columns, covariates = c("Alter","Geschlecht","Abschluss"))
pander(table_ANCOVA, style = "rmarkdown", fontsize = "tiny")
data_Pat_pre$time <- "pre"
data_Pat_post$time <- "post"
## Copy original dataframes
data_Pat_pre_comb <- data_Pat_pre
data_Pat_post_comb <- data_Pat_post
## Add timepoint-variable
data_Pat_pre_comb$time <- "pre"
data_Pat_post_comb$time <- "post"
data_Pat_pre_comb$Subject <- data_Pat_pre_comb$Subject + 600 # This was the ID given
View(data_Pat_pre_comb)
View(data_Pat_pre)
Patients_pre_vs_post <- rbind(data_Pat_post_comb, data_Pat_pre_comb)
View(Patients_pre_vs_post)
subject_counts <- table(Patients_pre_vs_post$Subject)
subject_counts
multiple_rows_subjects <- names(subject_counts)[subject_counts > 1]
Patients_pre_vs_post_clean <- Patients_pre_vs_post[Patients_pre_vs_post$Subject %in% multiple_rows_subjects, ]
## Calculate Raw Pearson Correlation and Test Significance
calculate_correlations_and_significance <- function(df_basis, cols) {
df <- data.frame(Correlation = numeric(length(cols)), t_statistic = numeric(length(cols)),
p_value = numeric(length(cols)))
rownames(df) <- cols
for (col in cols) {
# Get pre and post data using the new function
data <- get_pre_post_data(df_basis, col)
pre_data <- data$pre
post_data <- data$post
# Calculate Pearson correlation
correlation <- cor(pre_data, post_data)
# Calculate the t-statistic for the correlation
n <- length(pre_data)
t_statistic <- correlation * sqrt((n - 2) / (1 - correlation^2))
# Calculate the p-value for a one-tailed test (H_0: r ≤ 0)
p_value <- pt(t_statistic, df = n - 2, lower.tail = FALSE)
# Store the results
df[col, "Correlation"] <- round(correlation, 3)
df[col, "t_statistic"] <- round(t_statistic, 3)
df[col, "p_value"] <- round(p_value, 3)
}
return(df)
}
# Apply the correlation and significance test to your data
correlation_significance_table <- calculate_correlations_and_significance(df_basis = Patients_pre_vs_post_imp, cols = imp_columns)
#Helper function to avoid redundancy (Get pre and post data in one place for assumption and Welch test)
get_pre_post_data <- function(df_basis, col) {
pre_data <- df_basis[df_basis[["time"]] == "pre", col]
post_data <- df_basis[df_basis[["time"]] == "post", col]
return(list(pre = pre_data, post = post_data))
}
## Calculate Raw Pearson Correlation and Test Significance
calculate_correlations_and_significance <- function(df_basis, cols) {
df <- data.frame(Correlation = numeric(length(cols)), t_statistic = numeric(length(cols)),
p_value = numeric(length(cols)))
rownames(df) <- cols
for (col in cols) {
# Get pre and post data using the new function
data <- get_pre_post_data(df_basis, col)
pre_data <- data$pre
post_data <- data$post
# Calculate Pearson correlation
correlation <- cor(pre_data, post_data)
# Calculate the t-statistic for the correlation
n <- length(pre_data)
t_statistic <- correlation * sqrt((n - 2) / (1 - correlation^2))
# Calculate the p-value for a one-tailed test (H_0: r ≤ 0)
p_value <- pt(t_statistic, df = n - 2, lower.tail = FALSE)
# Store the results
df[col, "Correlation"] <- round(correlation, 3)
df[col, "t_statistic"] <- round(t_statistic, 3)
df[col, "p_value"] <- round(p_value, 3)
}
return(df)
}
# Apply the correlation and significance test to your data
correlation_significance_table <- calculate_correlations_and_significance(df_basis = Patients_pre_vs_post_imp, cols = imp_columns)
Patients_pre_vs_post_imp <- Patients_pre_vs_post_clean[,c("Subject",imp_columns,"time")]
View(Patients_pre_vs_post_imp)
## Calculate Raw Pearson Correlation and Test Significance
calculate_correlations_and_significance <- function(df_basis, cols) {
df <- data.frame(Correlation = numeric(length(cols)), t_statistic = numeric(length(cols)),
p_value = numeric(length(cols)))
rownames(df) <- cols
for (col in cols) {
# Get pre and post data using the new function
data <- get_pre_post_data(df_basis, col)
pre_data <- data$pre
post_data <- data$post
# Calculate Pearson correlation
correlation <- cor(pre_data, post_data)
# Calculate the t-statistic for the correlation
n <- length(pre_data)
t_statistic <- correlation * sqrt((n - 2) / (1 - correlation^2))
# Calculate the p-value for a one-tailed test (H_0: r ≤ 0)
p_value <- pt(t_statistic, df = n - 2, lower.tail = FALSE)
# Store the results
df[col, "Correlation"] <- round(correlation, 3)
df[col, "t_statistic"] <- round(t_statistic, 3)
df[col, "p_value"] <- round(p_value, 3)
}
return(df)
}
# Apply the correlation and significance test to your data
correlation_significance_table <- calculate_correlations_and_significance(df_basis = Patients_pre_vs_post_imp, cols = imp_columns)
pander(correlation_significance_table, style = "rmarkdown", fontsize = "tiny")
paired_t_test_mult_cols <- function(df_basis, cols) {
df <- data.frame(t_statistic = numeric(length(cols)), p_value = numeric(length(cols)),
group_mean_pre = numeric(length(cols)), group_mean_post = numeric(length(cols)),
cohen_d = numeric(length(cols)))
rownames(df) <- cols
for (col in cols) {
# Get pre and post data using get_pre_post_data helper function
data <- get_pre_post_data(df_basis, col)
pre_data <- na.omit(data$pre)
post_data <- na.omit(data$post)
# non-formula interface as before
results <- t.test(pre_data, post_data, paired = TRUE, var.equal = FALSE)
#Alternativ using formula method:
#results <- t.test(df_basis[[col]] ~ df_basis[["time"]], paired = TRUE, var.equal = FALSE)
# Calculate Cohen's d using the cohen.d function for paired samples (effect size)
cohen_d_result <- cohen.d(post_data, pre_data, paired = TRUE)
cohen_d <- cohen_d_result$estimate
# Calculate power using pwr.t.test
n <- length(pre_data)
power_result <- pwr.t.test(d = cohen_d, n = n, sig.level = 0.05, type = "paired", alternative = "greater")
#0.007? (Bonferroni)
power <- power_result$power
# Store the results
df[col, "t_statistic"] <- round(results$statistic, 2)
df[col, "p_value"] <- round(results$p.value, 2)
df[col, "group_mean_pre"] <- round(mean(pre_data), 2)
df[col, "sd_pre"] <- round(sd(pre_data), 2)
df[col, "group_mean_post"] <- round(mean(post_data), 2)
df[col, "sd_post"] <- round(sd(post_data), 2)
df[col, "cohen_d"] <- round(cohen_d, 2)
df[col, "power"] <- round(power, 2)
}
return(df)
}
t_test_table_pre_post <- paired_t_test_mult_cols(df_basis = Patients_pre_vs_post_imp, cols = BIS_columns_renamed)
paired_t_test_mult_cols <- function(df_basis, cols) {
df <- data.frame(t_statistic = numeric(length(cols)), p_value = numeric(length(cols)),
group_mean_pre = numeric(length(cols)), group_mean_post = numeric(length(cols)),
cohen_d = numeric(length(cols)))
rownames(df) <- cols
for (col in cols) {
# Get pre and post data using get_pre_post_data helper function
data <- get_pre_post_data(df_basis, col)
pre_data <- na.omit(data$pre)
post_data <- na.omit(data$post)
# non-formula interface as before
results <- t.test(pre_data, post_data, paired = TRUE, var.equal = FALSE)
#Alternativ using formula method:
#results <- t.test(df_basis[[col]] ~ df_basis[["time"]], paired = TRUE, var.equal = FALSE)
# Calculate Cohen's d using the cohen.d function for paired samples (effect size)
cohen_d_result <- cohen.d(post_data, pre_data, paired = TRUE)
cohen_d <- cohen_d_result$estimate
# Calculate power using pwr.t.test
n <- length(pre_data)
power_result <- pwr.t.test(d = cohen_d, n = n, sig.level = 0.05, type = "paired", alternative = "greater")
#0.007? (Bonferroni)
power <- power_result$power
# Store the results
df[col, "t_statistic"] <- round(results$statistic, 2)
df[col, "p_value"] <- round(results$p.value, 2)
df[col, "group_mean_pre"] <- round(mean(pre_data), 2)
df[col, "sd_pre"] <- round(sd(pre_data), 2)
df[col, "group_mean_post"] <- round(mean(post_data), 2)
df[col, "sd_post"] <- round(sd(post_data), 2)
df[col, "cohen_d"] <- round(cohen_d, 2)
df[col, "power"] <- round(power, 2)
}
return(df)
}
t_test_table_pre_post <- paired_t_test_mult_cols(df_basis = Patients_pre_vs_post_imp, cols = imp_columns)
test <- get_pre_post_data(Patients_pre_vs_post_imp, "SSRT")
complete_cases <- complete.cases(test$pre, test$post)
complete_cases
paired_t_test_mult_cols <- function(df_basis, cols) {
df <- data.frame(t_statistic = numeric(length(cols)), p_value = numeric(length(cols)),
group_mean_pre = numeric(length(cols)), group_mean_post = numeric(length(cols)),
cohen_d = numeric(length(cols)))
rownames(df) <- cols
for (col in cols) {
# Get pre and post data using get_pre_post_data helper function
data <- get_pre_post_data(df_basis, col)
# Use complete.cases to keep only rows where both pre and post are not NA
complete_cases <- complete.cases(data$pre, data$post)
pre_data <- data$pre[complete_cases]
post_data <- data$post[complete_cases]
# non-formula interface as before
results <- t.test(pre_data, post_data, paired = TRUE, var.equal = FALSE)
#Alternativ using formula method:
#results <- t.test(df_basis[[col]] ~ df_basis[["time"]], paired = TRUE, var.equal = FALSE)
# Calculate Cohen's d using the cohen.d function for paired samples (effect size)
cohen_d_result <- cohen.d(post_data, pre_data, paired = TRUE)
cohen_d <- cohen_d_result$estimate
# Calculate power using pwr.t.test
n <- length(pre_data)
power_result <- pwr.t.test(d = cohen_d, n = n, sig.level = 0.05, type = "paired", alternative = "greater")
#0.007? (Bonferroni)
power <- power_result$power
# Store the results
df[col, "t_statistic"] <- round(results$statistic, 2)
df[col, "p_value"] <- round(results$p.value, 2)
df[col, "group_mean_pre"] <- round(mean(pre_data), 2)
df[col, "sd_pre"] <- round(sd(pre_data), 2)
df[col, "group_mean_post"] <- round(mean(post_data), 2)
df[col, "sd_post"] <- round(sd(post_data), 2)
df[col, "cohen_d"] <- round(cohen_d, 2)
df[col, "power"] <- round(power, 2)
}
return(df)
}
t_test_table_pre_post <- paired_t_test_mult_cols(df_basis = Patients_pre_vs_post_imp, cols = imp_columns)
pander(t_test_table_pre_post)
