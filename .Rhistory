response_criterion = params$response_criterion)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
windowsFonts(Arial=windowsFont("Arial"))
library(readr)
library(dplyr)
library(ggplot2)
family = "Arial"
theme_set(theme_bw() + theme(text = element_text(family = family),
axis.title = element_text(size = 24),
axis.title.y = element_text(size = 24, margin = margin(r = 30)),
axis.text = element_text(size = 18),
#legend.text = element_text(size = 18),
strip.text = element_text(size = 20)
#plot.title = element_text(size = size_text, family = family)
#panel.spacing.x = unit(3, "lines")
))
# or theme_classic()
# Get all folders in the results folder (each containing the results of another model)
basic_path = "Y:\\Psythera"
path_results_folder = file.path(basic_path, "Projekte_Meinke\\Old_projects\\Labrotation_Rebecca\\2_Machine_learning\\Results\\RT_trimmed_RT_wrong_removed_outliers-removed\\response_FSQ")
results_folders <- list.files(path = path_results_folder, full.names = FALSE)
# Filter for new results
results_folders <- results_folders[grepl("final", results_folders)& !grepl("permuted", results_folders)]
# For each folder, save the performance_across_iters-file in dictionary
results_dict = list()
for (folder_name in results_folders) {
# Read the file and store it as a dictionary
results_dict[[folder_name]] <- read.delim(file.path(path_results_folder, folder_name,
"performance_across_iters.txt"))
}
# Combine results
combined_results <- bind_rows(results_dict, .id = "FolderName")
combined_results$X <- NULL
# Separate into regressor and classifier dataframes
classification_results <- combined_results[grepl("classifier", combined_results$FolderName), ]
regression_results <- combined_results[grepl("regressor", combined_results$FolderName), ]
create_classification_plot <- function(results_df){
# Create new model variable
results_df$Model <- ifelse(grepl("random_forest_classifier_yes_smote_oversampling", results_df$FolderName),
"Random Forest\n(OS: SMOTE)",
ifelse(grepl("random_forest_classifier_yes_simple", results_df$FolderName),
"Random Forest\n(OS: Simple)",
ifelse(grepl("random_forest_classifier_no_oversampling", results_df$FolderName),
"Random Forest\n(OS: no)",
ifelse(grepl("svm_classifier_yes_smote", results_df$FolderName),
"Rbf-SVM\n(OS: SMOTE)",
ifelse(grepl("svm_classifier_yes_simple", results_df$FolderName),
"Rbf-SVM\n(OS: Simple)",
ifelse(grepl("svm_classifier_no_oversampling", results_df$FolderName),
"Rbf-SVM\n(OS: no)", NA))))))
# Ensure correct ordering
results_df$Model <- factor(results_df$Model, levels = c("Random Forest\n(OS: SMOTE)","Random Forest\n(OS: Simple)","Random Forest\n(OS: no)","Rbf-SVM\n(OS: SMOTE)",
"Rbf-SVM\n(OS: Simple)","Rbf-SVM\n(OS: no)"))
# Define feature sets and specify colors
results_df$FeatureSet <- ifelse(grepl("clinical_features", results_df$FolderName),
"Clinical Features", "Clinical + Executive\nFunctioning Features")
colors <- c("Clinical Features" = "white", "Clinical + Executive\nFunctioning Features" = "#D3D3D3")
# Set factor levels for FeatureSet to control order in the plot
results_df$FeatureSet <- factor(results_df$FeatureSet, levels = c("Clinical Features", "Clinical + Executive\nFunctioning Features"))
# Create ggplot
plot <- ggplot(results_df, aes(x=FeatureSet, y=balanced_accuracy, fill=FeatureSet)) +
geom_violin(scale = "width") +
geom_jitter(size = 1, width = 0.2, height = 0) +
stat_summary(
geom = "point",
shape = 24,
fun = "mean",
col = "black",
fill = "red",
size = 3
) +
labs(y = "Balanced Accuracy",  x = "", fill = "Feature Set") +
scale_y_continuous(breaks = c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)) +
scale_fill_manual(values = colors) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none") +
geom_rect(data = subset(results_df, Model == "Random Forest\n(OS: SMOTE)"),
fill = NA, colour = "black", size = 1.5, xmin = -Inf,xmax = Inf,
ymin = -Inf,ymax = Inf) +
facet_wrap(~Model, nrow = 1)
return(plot)
}
classification_plot <- create_classification_plot(results_df = classification_results)
classification_plot
create_regression_plot <- function(results_df){
# Create new model variable
results_df$Model <- ifelse(grepl("random_forest_regressor", results_df$FolderName), "Random Forest",
ifelse(grepl("ridge_regressor", results_df$FolderName), "Ridge", NA))
# Define feature sets and specify colors
results_df$FeatureSet <- ifelse(grepl("clinical_features", results_df$FolderName),
"Clinical Features", "Clinical + Executive\nFunctioning Features")
colors <- c("Clinical Features" = "white", "Clinical + Executive\nFunctioning Features" = "#D3D3D3")
# Set factor levels for FeatureSet to control order in the plot
results_df$FeatureSet <- factor(results_df$FeatureSet, levels = c("Clinical Features", "Clinical + Executive\nFunctioning Features"))
# Create ggplot
plot <- ggplot(results_df, aes(x=FeatureSet, y=MSE, fill=FeatureSet)) +
geom_violin(scale = "width") +
geom_jitter(size = 1, width = 0.2, height = 0) +
stat_summary(
geom = "point",
shape = 24,
fun = "mean",
col = "black",
fill = "red",
size = 3
) +
labs(y = "Mean Squared Error",  x = "", fill = "Feature Set") +
scale_fill_manual(values = colors) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none") +
facet_wrap(~Model, nrow = 1)
return(plot)
}
regression_plot <- create_regression_plot(results_df = regression_results)
regression_plot
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
windowsFonts(Arial=windowsFont("Arial"))
library(readr)
library(dplyr)
library(ggplot2)
family = "Arial"
theme_set(theme_bw() + theme(text = element_text(family = family),
axis.title = element_text(size = 24),
axis.title.y = element_text(size = 24, margin = margin(r = 30)),
axis.text = element_text(size = 18),
#legend.text = element_text(size = 18),
strip.text = element_text(size = 20)
#plot.title = element_text(size = size_text, family = family)
#panel.spacing.x = unit(3, "lines")
))
# or theme_classic()
# Get all folders in the results folder (each containing the results of another model)
basic_path = "Y:\\Psythera"
path_results_folder = file.path(basic_path, "Projekte_Meinke\\Old_projects\\Labrotation_Rebecca\\2_Machine_learning\\Results\\RT_trimmed_RT_wrong_removed_outliers-removed\\response_BAT")
results_folders <- list.files(path = path_results_folder, full.names = FALSE)
# Filter for new results
results_folders <- results_folders[grepl("final", results_folders)& !grepl("permuted", results_folders)]
# For each folder, save the performance_across_iters-file in dictionary
results_dict = list()
for (folder_name in results_folders) {
# Read the file and store it as a dictionary
results_dict[[folder_name]] <- read.delim(file.path(path_results_folder, folder_name,
"performance_across_iters.txt"))
}
# Combine results
combined_results <- bind_rows(results_dict, .id = "FolderName")
combined_results$X <- NULL
# Separate into regressor and classifier dataframes
classification_results <- combined_results[grepl("classifier", combined_results$FolderName), ]
regression_results <- combined_results[grepl("regressor", combined_results$FolderName), ]
create_classification_plot <- function(results_df){
# Create new model variable
results_df$Model <- ifelse(grepl("random_forest_classifier_yes_smote_oversampling", results_df$FolderName),
"Random Forest\n(OS: SMOTE)",
ifelse(grepl("random_forest_classifier_yes_simple", results_df$FolderName),
"Random Forest\n(OS: Simple)",
ifelse(grepl("random_forest_classifier_no_oversampling", results_df$FolderName),
"Random Forest\n(OS: no)",
ifelse(grepl("svm_classifier_yes_smote", results_df$FolderName),
"Rbf-SVM\n(OS: SMOTE)",
ifelse(grepl("svm_classifier_yes_simple", results_df$FolderName),
"Rbf-SVM\n(OS: Simple)",
ifelse(grepl("svm_classifier_no_oversampling", results_df$FolderName),
"Rbf-SVM\n(OS: no)", NA))))))
# Ensure correct ordering
results_df$Model <- factor(results_df$Model, levels = c("Random Forest\n(OS: SMOTE)","Random Forest\n(OS: Simple)","Random Forest\n(OS: no)","Rbf-SVM\n(OS: SMOTE)",
"Rbf-SVM\n(OS: Simple)","Rbf-SVM\n(OS: no)"))
# Define feature sets and specify colors
results_df$FeatureSet <- ifelse(grepl("clinical_features", results_df$FolderName),
"Clinical Features", "Clinical + Executive\nFunctioning Features")
colors <- c("Clinical Features" = "white", "Clinical + Executive\nFunctioning Features" = "#D3D3D3")
# Set factor levels for FeatureSet to control order in the plot
results_df$FeatureSet <- factor(results_df$FeatureSet, levels = c("Clinical Features", "Clinical + Executive\nFunctioning Features"))
# Create ggplot
plot <- ggplot(results_df, aes(x=FeatureSet, y=balanced_accuracy, fill=FeatureSet)) +
geom_violin(scale = "width") +
geom_jitter(size = 1, width = 0.2, height = 0) +
stat_summary(
geom = "point",
shape = 24,
fun = "mean",
col = "black",
fill = "red",
size = 3
) +
labs(y = "Balanced Accuracy",  x = "", fill = "Feature Set") +
scale_y_continuous(breaks = c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)) +
scale_fill_manual(values = colors) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none") +
geom_rect(data = subset(results_df, Model == "Random Forest\n(OS: SMOTE)"),
fill = NA, colour = "black", size = 1.5, xmin = -Inf,xmax = Inf,
ymin = -Inf,ymax = Inf) +
facet_wrap(~Model, nrow = 1)
return(plot)
}
classification_plot <- create_classification_plot(results_df = classification_results)
classification_plot
create_regression_plot <- function(results_df){
# Create new model variable
results_df$Model <- ifelse(grepl("random_forest_regressor", results_df$FolderName), "Random Forest",
ifelse(grepl("ridge_regressor", results_df$FolderName), "Ridge", NA))
# Define feature sets and specify colors
results_df$FeatureSet <- ifelse(grepl("clinical_features", results_df$FolderName),
"Clinical Features", "Clinical + Executive\nFunctioning Features")
colors <- c("Clinical Features" = "white", "Clinical + Executive\nFunctioning Features" = "#D3D3D3")
# Set factor levels for FeatureSet to control order in the plot
results_df$FeatureSet <- factor(results_df$FeatureSet, levels = c("Clinical Features", "Clinical + Executive\nFunctioning Features"))
# Create ggplot
plot <- ggplot(results_df, aes(x=FeatureSet, y=MSE, fill=FeatureSet)) +
geom_violin(scale = "width") +
geom_jitter(size = 1, width = 0.2, height = 0) +
stat_summary(
geom = "point",
shape = 24,
fun = "mean",
col = "black",
fill = "red",
size = 3
) +
labs(y = "Mean Squared Error",  x = "", fill = "Feature Set") +
scale_fill_manual(values = colors) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none") +
facet_wrap(~Model, nrow = 1)
return(plot)
}
regression_plot <- create_regression_plot(results_df = regression_results)
regression_plot
create_classification_plot <- function(results_df){
# Create new model variable
results_df$Model <- ifelse(grepl("random_forest_classifier_yes_smote_oversampling", results_df$FolderName),
"Random Forest\n(OS: SMOTE)",
ifelse(grepl("random_forest_classifier_yes_simple", results_df$FolderName),
"Random Forest\n(OS: Simple)",
ifelse(grepl("random_forest_classifier_no_oversampling", results_df$FolderName),
"Random Forest\n(OS: no)",
ifelse(grepl("svm_classifier_yes_smote", results_df$FolderName),
"Rbf-SVM\n(OS: SMOTE)",
ifelse(grepl("svm_classifier_yes_simple", results_df$FolderName),
"Rbf-SVM\n(OS: Simple)",
ifelse(grepl("svm_classifier_no_oversampling", results_df$FolderName),
"Rbf-SVM\n(OS: no)", NA))))))
# Ensure correct ordering
results_df$Model <- factor(results_df$Model, levels = c("Random Forest\n(OS: SMOTE)","Random Forest\n(OS: Simple)","Random Forest\n(OS: no)","Rbf-SVM\n(OS: SMOTE)",
"Rbf-SVM\n(OS: Simple)","Rbf-SVM\n(OS: no)"))
# Define feature sets and specify colors
results_df$FeatureSet <- ifelse(grepl("clinical_features", results_df$FolderName),
"Clinical Features", "Clinical + Executive\nFunctioning Features")
colors <- c("Clinical Features" = "white", "Clinical + Executive\nFunctioning Features" = "#D3D3D3")
# Set factor levels for FeatureSet to control order in the plot
results_df$FeatureSet <- factor(results_df$FeatureSet, levels = c("Clinical Features", "Clinical + Executive\nFunctioning Features"))
# Create ggplot
plot <- ggplot(results_df, aes(x=FeatureSet, y=auc, fill=FeatureSet)) +
geom_violin(scale = "width") +
geom_jitter(size = 1, width = 0.2, height = 0) +
stat_summary(
geom = "point",
shape = 24,
fun = "mean",
col = "black",
fill = "red",
size = 3
) +
labs(y = "Balanced Accuracy",  x = "", fill = "Feature Set") +
scale_y_continuous(breaks = c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)) +
scale_fill_manual(values = colors) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none") +
geom_rect(data = subset(results_df, Model == "Random Forest\n(OS: SMOTE)"),
fill = NA, colour = "black", size = 1.5, xmin = -Inf,xmax = Inf,
ymin = -Inf,ymax = Inf) +
facet_wrap(~Model, nrow = 1)
return(plot)
}
classification_plot <- create_classification_plot(results_df = classification_results)
classification_plot
# Get all folders in the results folder (each containing the results of another model)
basic_path = "Y:\\Psythera"
path_results_folder = file.path(basic_path, "Projekte_Meinke\\Old_projects\\Labrotation_Rebecca\\2_Machine_learning\\Results\\RT_trimmed_RT_wrong_removed_outliers-removed\\response_FSQ")
results_folders <- list.files(path = path_results_folder, full.names = FALSE)
# Filter for new results
results_folders <- results_folders[grepl("final", results_folders)& !grepl("permuted", results_folders)]
# For each folder, save the performance_across_iters-file in dictionary
results_dict = list()
for (folder_name in results_folders) {
# Read the file and store it as a dictionary
results_dict[[folder_name]] <- read.delim(file.path(path_results_folder, folder_name,
"performance_across_iters.txt"))
}
# Combine results
combined_results <- bind_rows(results_dict, .id = "FolderName")
combined_results$X <- NULL
# Separate into regressor and classifier dataframes
classification_results <- combined_results[grepl("classifier", combined_results$FolderName), ]
regression_results <- combined_results[grepl("regressor", combined_results$FolderName), ]
create_classification_plot <- function(results_df){
# Create new model variable
results_df$Model <- ifelse(grepl("random_forest_classifier_yes_smote_oversampling", results_df$FolderName),
"Random Forest\n(OS: SMOTE)",
ifelse(grepl("random_forest_classifier_yes_simple", results_df$FolderName),
"Random Forest\n(OS: Simple)",
ifelse(grepl("random_forest_classifier_no_oversampling", results_df$FolderName),
"Random Forest\n(OS: no)",
ifelse(grepl("svm_classifier_yes_smote", results_df$FolderName),
"Rbf-SVM\n(OS: SMOTE)",
ifelse(grepl("svm_classifier_yes_simple", results_df$FolderName),
"Rbf-SVM\n(OS: Simple)",
ifelse(grepl("svm_classifier_no_oversampling", results_df$FolderName),
"Rbf-SVM\n(OS: no)", NA))))))
# Ensure correct ordering
results_df$Model <- factor(results_df$Model, levels = c("Random Forest\n(OS: SMOTE)","Random Forest\n(OS: Simple)","Random Forest\n(OS: no)","Rbf-SVM\n(OS: SMOTE)",
"Rbf-SVM\n(OS: Simple)","Rbf-SVM\n(OS: no)"))
# Define feature sets and specify colors
results_df$FeatureSet <- ifelse(grepl("clinical_features", results_df$FolderName),
"Clinical Features", "Clinical + Executive\nFunctioning Features")
colors <- c("Clinical Features" = "white", "Clinical + Executive\nFunctioning Features" = "#D3D3D3")
# Set factor levels for FeatureSet to control order in the plot
results_df$FeatureSet <- factor(results_df$FeatureSet, levels = c("Clinical Features", "Clinical + Executive\nFunctioning Features"))
# Create ggplot
plot <- ggplot(results_df, aes(x=FeatureSet, y=auc, fill=FeatureSet)) +
geom_violin(scale = "width") +
geom_jitter(size = 1, width = 0.2, height = 0) +
stat_summary(
geom = "point",
shape = 24,
fun = "mean",
col = "black",
fill = "red",
size = 3
) +
labs(y = "Balanced Accuracy",  x = "", fill = "Feature Set") +
scale_y_continuous(breaks = c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)) +
scale_fill_manual(values = colors) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none") +
geom_rect(data = subset(results_df, Model == "Random Forest\n(OS: SMOTE)"),
fill = NA, colour = "black", size = 1.5, xmin = -Inf,xmax = Inf,
ymin = -Inf,ymax = Inf) +
facet_wrap(~Model, nrow = 1)
return(plot)
}
classification_plot <- create_classification_plot(results_df = classification_results)
classification_plot
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(kableExtra)
library(haven)
library(tidyverse)
if (params$outliers_removed == "yes"){
outliers_suffix = "outliers-removed"
} else if (params$outliers_removed == "no"){
outliers_suffix = "outliers-not-removed"
}
basic_path_dataprep <- params$input_data_path
basic_path_results_FSQ <- file.path(basic_path_dataprep, "BIS", outliers_suffix, "response_FSQ")
basic_path_results_BAT <- file.path(basic_path_dataprep, "BIS", outliers_suffix, "response_BAT")
dir.create(basic_path_results_FSQ, recursive = TRUE)
dir.create(basic_path_results_BAT, recursive = TRUE)
basic_path_taskdata <- file.path(basic_path_dataprep,"raw_data")
dir.create(basic_path_taskdata, recursive = TRUE)
AllData_NumbLet <- read.csv(file.path(basic_path_taskdata,"AllData_NumbLet.csv"))
AllData_Stroop <- read.csv(file.path(basic_path_taskdata,"AllData_Stroop.csv"))
AllData_TwoBack <- read.csv(file.path(basic_path_taskdata,"AllData_TwoBack.csv"))
AllData_SST <- read.csv(file.path(basic_path_taskdata,"AllData_SST.csv"))
basic_path_socdemdata <- "Y:/PsyThera/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Rohdaten/CRC_C5_Hilbert/CRC_C5_Hilbert"
data_socdem_clin <- haven::read_dta(file.path(basic_path_socdemdata, 'Data_Kevin_28.07.23.dta'))
data_socdem_clin <- data_socdem_clin %>%
rename(Subject = id)
data_socdem_clin <- data_socdem_clin%>%
filter(Dropout != 1)
data_BAT <- haven::read_dta(file.path(basic_path_socdemdata, 'TaskBattery.dta'))
data_BAT <- data_BAT %>%
rename(Subject = stid)
task_data <- AllData_NumbLet %>%
left_join(AllData_Stroop, by = "Subject") %>%
left_join(AllData_TwoBack, by = "Subject") %>%
left_join(AllData_SST, by = "Subject")
# Change variable names
task_data <- task_data %>%
rename(NumbLet_Average_RT = Overall_RT.x,
NumbLet_Average_PC = Overall_PC.x,
Stroop_Average_RT = Overall_RT.y,
Stroop_Average_PC = Overall_PC.y,
TwoBack_Average_RT = Overall_RT,
TwoBack_Average_PC = Overall_PC,
)
# Define column categories
wm_cols <- c("Foil_RT","Target_RT","Foil_PC","Target_PC","TwoBack_Average_RT","TwoBack_Average_PC")
stroop_cols <-c("Congruent_RT","Incongruent_RT","Congruent_PC","Incongruent_PC","Stroop_Average_RT","Stroop_Average_PC")
numblet_cols <- c("Repeat_RT","Switch_RT","Repeat_PC","Switch_PC","NumbLet_Average_RT")
task_data[task_data$Subject == 1,c("Subject")] <- 216001
task_data[task_data$Subject == 2160031,c("Subject")] <- 216603
task_data[task_data$Subject == 216504,c("Subject")] <- 216604
task_data[task_data$Subject == 2166108,c("Subject")] <- 216708
task_data[task_data$Subject == 2166120,c("Subject")] <- 216720
task_data[task_data$Subject == 2166121,c("Subject")] <- 216721
# Add group information / membership
task_data <- task_data %>%
left_join(data_socdem_clin %>% select(Subject, Gruppe),
by = "Subject")
# Assign post IDs (Gruppe = 2). Subjects measured a second time (post-treatment) got an ID adding 600 to their original ID
task_data <- task_data %>%
mutate(Subject = as.numeric(Subject),
Gruppe = ifelse(Subject != 2160321 & Subject >= 216601 & (Subject - 600) %in% Subject, 2, Gruppe))
# Get subjects without group
task_data[is.na(task_data$Gruppe),]$Subject
# Remove subjects with missing group information.
task_data_clean_group <- task_data %>%
filter(!is.na(Gruppe))
# Get subjects that are in the sociodemographic data but are not in the task data.
data_socdem_clin$Subject[!data_socdem_clin$Subject %in% task_data_clean_group$Subject]
task_data_clean_group[task_data_clean_group$Subject == 216032, stroop_cols] <- NA
task_data_clean_group[task_data_clean_group$Subject == 216107, stroop_cols] <- NA
task_data_clean_group[task_data_clean_group$Subject == 216137, stroop_cols] <- NA
if (params$outliers_removed == "yes"){
wm_condition <- which(task_data_clean_group$Foil_PC< 0.35|task_data_clean_group$Target_PC< 0.15)
stroop_condition <- which(task_data_clean_group$Congruent_PC< 0.5|task_data_clean_group$Incongruent_PC< 0.5)
numblet_condition <- which(task_data_clean_group$Switch_PC< 0.5|task_data_clean_group$Repeat_PC< 0.5)
# Set all measures belonging to the task as NA if one condition is an outlier
task_data_clean <- task_data_clean_group
task_data_clean[wm_condition,wm_cols] <- NA
task_data_clean[stroop_condition,stroop_cols] <- NA
task_data_clean[numblet_condition,numblet_cols] <- NA
# Get the subjects
cat("2-back task", task_data_clean[wm_condition,c("Subject")])
cat("Stroop task", task_data_clean[stroop_condition,c("Subject")])
cat("Number-letter task", task_data_clean[numblet_condition,c("Subject")])
} else {
task_data_clean <- task_data_clean_group
}
## Step 1: Calculate mean and SD for RT and PC across all healthy subjects and all conditions
NumbLet_mean_sd_HC <- task_data_clean %>%
filter(Gruppe == 0) %>%
select(NumbLet_Average_RT, NumbLet_Average_PC) %>%
summarise(meanRT = mean(NumbLet_Average_RT, na.rm = TRUE),
meanPC = mean(NumbLet_Average_PC, na.rm = TRUE),
sdRT = sd(NumbLet_Average_RT, na.rm = TRUE),
sdPC = sd(NumbLet_Average_PC, na.rm = TRUE))
## Step 2: Standardize RT and PC for each condition
task_data_clean <- task_data_clean %>%
mutate(Z_Repeat_RT = (Repeat_RT - NumbLet_mean_sd_HC$meanRT) / NumbLet_mean_sd_HC$sdRT,
Z_Switch_RT = (Switch_RT - NumbLet_mean_sd_HC$meanRT) / NumbLet_mean_sd_HC$sdRT,
Z_Repeat_PC = (Repeat_PC - NumbLet_mean_sd_HC$meanPC) / NumbLet_mean_sd_HC$sdPC,
Z_Switch_PC = (Switch_PC - NumbLet_mean_sd_HC$meanPC) / NumbLet_mean_sd_HC$sdPC)
# Step 3: Calculate BIS(Repeat), BIS(Switch) and Difference Score
task_data_clean <- task_data_clean %>%
mutate(NumberLetter_BIS_Repeat = Z_Repeat_PC - Z_Repeat_RT,
NumberLetter_BIS_Switch = Z_Switch_PC - Z_Switch_RT) %>%
mutate(NumberLetter_BIS_Diff_Score = NumberLetter_BIS_Switch - NumberLetter_BIS_Repeat)
boxplot(task_data_clean$NumberLetter_BIS_Diff_Score, main = "Number-Letter BIS Difference Score")
## Step 1: Calculate mean and SD for RT and PC across all healthy subjects and all conditions
Stroop_mean_sd_HC <- task_data_clean %>%
filter(Gruppe == 0) %>%
select(Stroop_Average_RT, Stroop_Average_PC) %>%
summarise(meanRT = mean(Stroop_Average_RT, na.rm = TRUE),
meanPC = mean(Stroop_Average_PC, na.rm = TRUE),
sdRT = sd(Stroop_Average_RT, na.rm = TRUE),
sdPC = sd(Stroop_Average_PC, na.rm = TRUE))
## Step 2: Standardize RT and PC for each condition
task_data_clean <- task_data_clean %>%
mutate(Z_Congruent_RT = (Congruent_RT - Stroop_mean_sd_HC$meanRT) / Stroop_mean_sd_HC$sdRT,
Z_Incongruent_RT = (Incongruent_RT - Stroop_mean_sd_HC$meanRT) / Stroop_mean_sd_HC$sdRT,
Z_Congruent_PC = (Congruent_PC - Stroop_mean_sd_HC$meanPC) / Stroop_mean_sd_HC$sdPC,
Z_Incongruent_PC = (Incongruent_PC - Stroop_mean_sd_HC$meanPC) / Stroop_mean_sd_HC$sdPC)
# Step 3: Calculate BIS(Congruent), BIS(Incongruent) and Difference Score
task_data_clean <- task_data_clean %>%
mutate(Stroop_BIS_Congruent = Z_Congruent_PC - Z_Congruent_RT,
Stroop_BIS_Incongruent = Z_Incongruent_PC - Z_Incongruent_RT) %>%
mutate(Stroop_BIS_Diff_Score = Stroop_BIS_Incongruent - Stroop_BIS_Congruent)
boxplot(task_data_clean$Stroop_BIS_Diff_Score, main = "Stroop BIS Difference Score")
## Step 1: Calculate mean and SD for RT and PC across all healthy subjects and all conditions
TwoBack_mean_sd_HC <- task_data_clean %>%
filter(Gruppe == 0) %>%
select(TwoBack_Average_RT, TwoBack_Average_PC) %>%
summarise(meanRT = mean(TwoBack_Average_RT, na.rm =TRUE),
meanPC = mean(TwoBack_Average_PC, na.rm =TRUE),
sdRT = sd(TwoBack_Average_RT, na.rm =TRUE),
sdPC = sd(TwoBack_Average_PC, na.rm =TRUE))
## Step 2: Standardize RT and PC for each condition
task_data_clean <- task_data_clean %>%
mutate(Z_Total_RT = (TwoBack_Average_RT - TwoBack_mean_sd_HC$meanRT) / TwoBack_mean_sd_HC$sdRT,
Z_Target_RT = (Target_RT - TwoBack_mean_sd_HC$meanRT) / TwoBack_mean_sd_HC$sdRT,
Z_Foil_RT = (Foil_RT - TwoBack_mean_sd_HC$meanRT) / TwoBack_mean_sd_HC$sdRT,
Z_Total_PC = (TwoBack_Average_PC - TwoBack_mean_sd_HC$meanPC) / TwoBack_mean_sd_HC$sdPC,
Z_Target_PC = (Target_PC - TwoBack_mean_sd_HC$meanPC) / TwoBack_mean_sd_HC$sdPC,
Z_Foil_PC = (Foil_PC - TwoBack_mean_sd_HC$meanPC) / TwoBack_mean_sd_HC$sdPC)
# Calculate BIS(Target), BIS(Total) and BIS_Foil
task_data_clean <- task_data_clean %>%
mutate(TwoBack_BIS_Total = Z_Total_PC - Z_Total_RT,
TwoBack_BIS_Target = Z_Target_PC - Z_Target_RT,
TwoBack_BIS_Foil = Z_Foil_PC - Z_Foil_RT)
boxplot(task_data_clean$TwoBack_BIS_Total, main = "TwoBack BIS Difference Score")
write.csv(task_data_clean, file.path(basic_path_results_FSQ, "Task_Performance_Scores.csv"), row.names = FALSE)
write.csv(task_data_clean, file.path(basic_path_results_BAT, "Task_Performance_Scores.csv"), row.names = FALSE)
# Reduce task data
task_data_clean_imp <- task_data_clean %>%
select(Subject, Gruppe, NumberLetter_BIS_Repeat, NumberLetter_BIS_Switch, NumberLetter_BIS_Diff_Score, Repeat_n_trimmed_removed_RT, Repeat_n_wrong_removed_RT, Switch_n_trimmed_removed_RT, Switch_n_wrong_removed_RT, Stroop_BIS_Congruent, Stroop_BIS_Incongruent, Stroop_BIS_Diff_Score,Congruent_n_trimmed_removed_RT, Congruent_n_wrong_removed_RT, Incongruent_n_trimmed_removed_RT, Incongruent_n_wrong_removed_RT,TwoBack_BIS_Foil, TwoBack_BIS_Target, TwoBack_BIS_Total, Foil_n_trimmed_removed_RT, Foil_n_wrong_removed_RT,
Target_n_trimmed_removed_RT, Target_n_wrong_removed_RT,SSRT)
cols_soc_imp <- c("Subject", "Geschlecht", "Alter","Abschluss","T1_BAT_FAS_score","T3_BAT_FAS_score",
"T1_BAT_BDI_II_score","T1_BAT_STAI_T_score","T1_BAT_BIS_11_score","T1_BAT_Kirby_k_score",
"T1_BAT_CFC_14_score","T1_BAT_SRHI_score")
# Add sociodem. & clinical data
all_data_clean_imp <- left_join(x = task_data_clean_imp,
y = data_socdem_clin %>% select(all_of(cols_soc_imp)),
by = "Subject")
all_data_clean_imp <- left_join(x = all_data_clean_imp,
y = data_BAT %>% select(Subject, BAT_T1, BAT_T3),
by = "Subject")
data_socdem_clin <-data_socdem_clin %>%
mutate(Response = ifelse(is.na(T1_BAT_FAS_score) | is.na(T3_BAT_FAS_score), NA,
ifelse((T1_BAT_FAS_score - T3_BAT_FAS_score) >= 0.5 * T1_BAT_FAS_score, 1, 0)))
data_socdem_clin[,c("T1_BAT_FAS_score","T3_BAT_FAS_score","Response")]
