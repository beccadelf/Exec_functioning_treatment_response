BIS_columns <- BIS_columns[BIS_columns != "T1_BAT_BIS_11_score"] # BIS-11 is a questionnaire
imp_columns <- c(BIS_columns,"SSRT")
Patients_vs_HC_imp <- Patients_vs_HC[,c("Subject","Gruppe",imp_columns)]
## 3. Add confounds (Alter, Geschlecht, Abschluss)
Patients_vs_HC_imp_conf <- merge(Patients_vs_HC[,c("Subject","Alter","Geschlecht","Abschluss")], Patients_vs_HC_imp, by = "Subject")
# t_test_mult_cols <- function(df_basis, cols) {
#   # Calculate a t-test for multiple comparisons and store the results in a dataframe
#   df <- data.frame(group_mean_Patients = numeric(length(cols)), sd_Patients = numeric(length(cols)),
#                    group_mean_HC = numeric(length(cols)), sd_HC = numeric(length(cols)),df = numeric(length(cols)), t_statistic = numeric(length(cols)), p_value = numeric(length(cols)),
#                    cohen_d = numeric(length(cols)))
#   rownames(df) <- cols
#   p_values_raw <- numeric(length(cols))  # Vector to store raw p-values
#
#   for (i in seq_along(cols)) {
#     col <- cols[i] #seq_along for sequencing column indices
#
#     # Using the non-formula interface
#     group0 <- na.omit(df_basis[df_basis[["Gruppe"]] == 0, col])
#     group1 <- na.omit(df_basis[df_basis[["Gruppe"]] == 1, col])
#     results <- t.test(group0, group1, paired = FALSE, var.equal = FALSE)
#     #Alternativ using formula method:
#       #results <- t.test(df_basis[[col]] ~ df_basis[["Gruppe"]], paired = FALSE, var.equal = FALSE)
#
#     # Store raw p-values for BH correction
#     p_values_raw[i] <- results$p.value
#
#     # Calculate Cohen's d using the cohen.d function (effect size)
#     cohen_d_result <- cohen.d(group0, group1, hedges.correction = FALSE)
#     cohen_d <- cohen_d_result$estimate
#
#     # Calculate power using pwr.t.test
#     n0 <- length(group0)
#     n1 <- length(group1)
#     power_result <- pwr.t.test(d = cohen_d, n = min(n0, n1), sig.level = 0.05, type = "two.sample", alternative = "greater")
#     power <- power_result$power
#
#     # Store the results
#     df[col, "t_statistic"] <- round(results$statistic, 2)
#     df[col, "df"] <- round(results[["parameter"]][["df"]], 2)
#     df[col, "p_value"] <- round(results$p.value, 2)
#     df[col, "group_mean_Patients"] <- round(mean(group1), 2)
#     df[col, "sd_Patients"] <- round(sd(group1), 2)
#     df[col, "group_mean_HC"] <- round(mean(group0), 2)
#     df[col, "sd_HC"] <- round(sd(group0), 2)
#     df[col, "cohen_d"] <- round(cohen_d, 2)
#     df[col, "power"] <- round(power, 2)
#   }
#
#   # Adjust p-values using Benjamini-Hochberg method for multiple testing of related tasks
#   p_values_adjusted <- p.adjust(p_values_raw, method = "BH")
#   df$p_value_adjusted <- round(p_values_adjusted, 2)
#
#   return(df)
# }
ttest_results_columns <- c(
"group_mean_Patients", "sd_Patients",
"group_mean_HC", "sd_HC",
"df", "t_statistic", "p_value", "cohen_d", "power"
)
# t_test_table <- t_test_mult_cols(df_basis = Patients_vs_HC_imp, cols = imp_columns)
# #pander(t_test_table, style = "rmarkdown", fontsize = "tiny")
# t_test_table
t_test_table <- t_test_mult_cols(df_basis = Patients_vs_HC_imp, cols = imp_columns, df_results_columns = ttest_results_columns, grouping_variable = "Gruppe")
View(t_test_table)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(tidyr)
library(pander)
library(effsize)
library(pwr)
library(gtsummary)
library(gt)
library(car)
library(flextable)
# User-defined functions
source("../Useful_functions.R")
format_flextable_portrait <- flextable_settings(word_orientation = "portrait")
library(officer)
format_flextable_portrait <- flextable_settings(word_orientation = "portrait")
format_flextable_landscape <- flextable_settings(word_orientation = "landscape")
# # Flextable
# set_flextable_defaults(font.family = "Arial",
#                        font.size = 8,
#                        padding.bottom = 3,
#                        padding.top = 3,
#                        padding.left = 0.5,
#                        paddings.right = 0.5,
#                        #theme_fun = "theme_apa",
#                        theme_fun = NULL,
#                        text.align = "center",
#                        line_spacing = 1.5)
#
# # Word documents to save flextables
# margins <- page_mar(
#   bottom = 2 / 2.54,
#   top = 2.5 / 2.54,
#   right = 2.5 / 2.54,
#   left = 2.5 / 2.54,
#   header = 0.5,
#   footer = 0.5,
#   gutter = 0.5
# )
#
# format_table_wide <- prop_section(
#   page_size = page_size(orient = "landscape"),
#   page_margins = margins)
#
# format_table_long <- prop_section(
#   page_size = page_size(orient = "portrait"),
#   page_margins = margins
# )
basic_path = "Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/0_Datapreparation/Daten_Gruppenvergleich/With_wrong_responses/outliers-removed"
param_suffix = basename(basic_path)
data_Pat_pre <- read.csv(file.path(basic_path,"Data_Patients_Pre.csv"))
data_Pat_pre_clean <- data_Pat_pre[!is.na(data_Pat_pre$Response),]
# Ensure "Response" is treated as a factor
data_Pat_pre_clean$Response <- as.factor(data_Pat_pre_clean$Response)
# Define the columns for which to perform the test (i.e., task performance measures)
imp_columns <- c("NumberLetter_BIS_Repeat", "NumberLetter_BIS_Switch",
"NumberLetter_BIS_Diff_Score", "Stroop_BIS_Congruent",
"Stroop_BIS_Incongruent", "Stroop_BIS_Diff_Score",
"TwoBack_BIS_Foil", "TwoBack_BIS_Target", "TwoBack_BIS_Total",
"SSRT")
ttest_results_columns <- c(
"group_mean_Response", "sd_Response",
"group_mean_NonReponse", "sd_NonResponse",
"df", "t_statistic", "p_value", "cohen_d", "power"
)
t_test_table <- t_test_mult_cols(df_basis = data_Pat_pre_clean, cols = imp_columns, df_results_columns = ttest_results_columns, grouping_variable = "Response")
#pander(t_test_table, style = "rmarkdown", fontsize = "tiny")
t_test_table
# # Perform t-tests for each task and store results
# t_test_mult_cols <- function(df_basis, cols) {
#   # Initialize empty dataframe
#   df <- data.frame(group_mean_Response = numeric(length(cols)), sd_Response = numeric(length(cols)),
#                    group_mean_NonResponse = numeric(length(cols)), sd_NonResponse = numeric(length(cols)),
#                    df = numeric(length(cols)), t_statistic = numeric(length(cols)),
#                    p_value = numeric(length(cols)), cohen_d = numeric(length(cols)))
#   rownames(df) <- cols
#   p_values_raw <- numeric(length(cols))  # Vector to store raw p-values
#
#   for (i in seq_along(cols)) {
#     col <- cols[i]
#
#     # Separate groups by Response = 1 and Response = 0
#     group1 <- na.omit(df_basis[df_basis[["Response"]] == 1, col])
#     group0 <- na.omit(df_basis[df_basis[["Response"]] == 0, col])
#     #Alternativ using formula method:
#       #results <- t.test(df_basis[[col]] ~ df_basis[["Response"]], paired = FALSE, var.equal = TRUE)
#
#     # Perform standard t-test (since variance homogeneity holds)
#     results <- t.test(group1, group0, paired = FALSE, var.equal = TRUE)
#
#     # Store raw p-values for BH correction
#     p_values_raw[i] <- results$p.value
#
#     # Calculate Cohen's d
#     cohen_d_result <- cohen.d(group1, group0, hedges.correction = FALSE)
#     cohen_d <- cohen_d_result$estimate
#
#     # Calculate power
#     n0 <- length(group0)
#     n1 <- length(group1)
#     power_result <- pwr.t.test(d = cohen_d, n = min(n0, n1), sig.level = 0.05, type = "two.sample", alternative = "greater")
#     power <- power_result$power
#
#     # Store the results
#     df[col, "t_statistic"] <- round(results$statistic, 2)
#     df[col, "df"] <- round(results[["parameter"]][["df"]], 2)
#     df[col, "p_value"] <- round(results$p.value, 2)
#     df[col, "group_mean_Response"] <- round(mean(group1), 2)
#     df[col, "sd_Response"] <- round(sd(group1), 2)
#     df[col, "group_mean_NonResponse"] <- round(mean(group0), 2)
#     df[col, "sd_NonResponse"] <- round(sd(group0), 2)
#     df[col, "cohen_d"] <- round(cohen_d, 2)
#     df[col, "power"] <- round(power, 2)
#   }
#
#   # Adjust p-values using Benjamini-Hochberg method for multiple testing of related tasks
#   p_values_adjusted <- p.adjust(p_values_raw, method = "BH")
#   df$p_value_adjusted <- round(p_values_adjusted, 2)
#
#   return(df)
# }
View(t_test_table)
t_test_table_pub <- cbind(performance_measures = rownames(t_test_table), t_test_table)
# Combine "Mean" and "SD" columns and reduce dataframe
t_test_table_pub <- t_test_table_pub %>%
mutate(
`Responder Mean (SD)` = paste0(round(group_mean_Response, 2), " (", round(sd_Response, 2), ")"),
`Nonresponder Mean (SD)` = paste0(round(group_mean_NonResponse, 2), " (", round(sd_NonResponse, 2), ")")
) %>%
select(performance_measures, `Responder Mean (SD)`, `Nonresponder Mean (SD)`, df, t_statistic, p_value, p_value_adjusted)
View(t_test_table_pub)
colnames(t_test_table_pub)
t_test_table_pub <- cbind(performance_measures = rownames(t_test_table), t_test_table)
# Combine "Mean" and "SD" columns and reduce dataframe
t_test_table_pub <- t_test_table_pub %>%
mutate(
`Responder Mean (SD)` = paste0(round(group_mean_Response, 2), " (", round(sd_Response, 2), ")"),
`Nonresponder Mean (SD)` = paste0(round(group_mean_NonReponse, 2), " (", round(sd_NonResponse, 2), ")")
) %>%
select(performance_measures, `Responder Mean (SD)`, `Nonresponder Mean (SD)`, df, t_statistic, p_value, p_value_adjusted)
# Rename performance measures using a named vector
rename_map <- c(
'NumberLetter_BIS_Repeat' = "Number-Letter: Repeat",
'NumberLetter_BIS_Switch' = "Number-Letter: Switch",
'NumberLetter_BIS_Diff_Score' = "Number-Letter: Switch - Repeat",
'Stroop_BIS_Congruent' = "Stroop: Congruent",
'Stroop_BIS_Incongruent' = "Stroop: Incongruent",
'Stroop_BIS_Diff_Score' = "Stroop: Incongruent - Congruent",
'TwoBack_BIS_Foil' = "2-Back: Foil",
'TwoBack_BIS_Target' = "2-Back: Target",
'TwoBack_BIS_Total' = "2-Back: Total",
'SSRT' = "Stop-Signal RT")
t_test_table_pub$performance_measures <- rename_map[t_test_table_pub$performance_measures]
# Change colnames
colnames(t_test_table_pub) <- c("Performance Measure", "Responder Mean (SD)", "Non-Responder Mean (SD)", "df", "t-Statistic", "p-Value", "adj. p-Value")
ft_t_test <- flextable(t_test_table_pub)
# Set table properties
ft_t_test <- set_table_properties(ft_t_test, width = 1, layout = "autofit")
# Header in bold
ft_t_test <- bold(ft_t_test, bold = TRUE, part = "header")
# Alignments
ft_t_test <- align(ft_t_test, j = 1, align = "left", part = "all") # first column
ft_t_test <- align(ft_t_test, j = 2:ncol(t_test_table_pub), align = "center", part = "all") # rest
# Export flextable
save_as_docx(
ft_t_test,
path = "Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/Submission/Tables/t-test_Responder_Nonresponder.docx",
pr_section = format_flextable_portrait)
View(t_test_table)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(tidyr)
library(pander)
library(effsize)
library(pwr)
library(gtsummary)
library(gt)
library(car)
library(flextable)
library(officer)
# User-defined functions
source("../Useful_functions.R")
format_flextable_portrait <- flextable_settings(word_orientation = "portrait")
format_flextable_landscape <- flextable_settings(word_orientation = "landscape")
basic_path = params$input_data_path
data_HC <- read.csv(file.path(basic_path,"Data_HC.csv"))
data_Pat_pre <- read.csv(file.path(basic_path,"Data_Patients_Pre.csv"))
## 1. Merge patients pre and controls
Patients_vs_HC <- rbind(data_Pat_pre, data_HC)
## 2. Reduce dataset to executive functions of interest (BIS columns and SSRT)
BIS_columns <- colnames(Patients_vs_HC)[grep("BIS", colnames(Patients_vs_HC))]
BIS_columns <- BIS_columns[BIS_columns != "T1_BAT_BIS_11_score"] # BIS-11 is a questionnaire
imp_columns <- c(BIS_columns,"SSRT")
Patients_vs_HC_imp <- Patients_vs_HC[,c("Subject","Gruppe",imp_columns)]
## 3. Add confounds (Alter, Geschlecht, Abschluss)
Patients_vs_HC_imp_conf <- merge(Patients_vs_HC[,c("Subject","Alter","Geschlecht","Abschluss")], Patients_vs_HC_imp, by = "Subject")
ttest_results_columns <- c(
"group_mean_Patients", "sd_Patients",
"group_mean_HC", "sd_HC",
"df", "t_statistic", "p_value", "cohen_d", "power"
)
df_results <- data.frame(matrix(NA, nrow = length(imp_columns), ncol = length(ttest_results_columns)))
View(df_results)
colnames(df_results) <- ttest_results_columns
rownames(df_results) <- imp_columns
p_values_raw <- numeric(length(imp_columns))
group0 <- na.omit(Patients_vs_HC_imp[Patients_vs_HC_imp[["Gruppe"]] == 0, "NumberLetter_BIS_Repeat"])
group1 <- na.omit(Patients_vs_HC_imp[Patients_vs_HC_imp[["Gruppe"]] == 1, "NumberLetter_BIS_Repeat"])
results <- t.test(group0, group1, paired = FALSE, var.equal = FALSE)
View(results)
test <- round(results$parameter["df"], 2)
class(test)
test
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(tidyr)
library(pander)
library(effsize)
library(pwr)
library(gtsummary)
library(gt)
library(car)
library(flextable)
library(officer)
# User-defined functions
source("../Useful_functions.R")
format_flextable_portrait <- flextable_settings(word_orientation = "portrait")
format_flextable_landscape <- flextable_settings(word_orientation = "landscape")
basic_path = params$input_data_path
data_HC <- read.csv(file.path(basic_path,"Data_HC.csv"))
data_Pat_pre <- read.csv(file.path(basic_path,"Data_Patients_Pre.csv"))
## 1. Merge patients pre and controls
Patients_vs_HC <- rbind(data_Pat_pre, data_HC)
## 2. Reduce dataset to executive functions of interest (BIS columns and SSRT)
BIS_columns <- colnames(Patients_vs_HC)[grep("BIS", colnames(Patients_vs_HC))]
BIS_columns <- BIS_columns[BIS_columns != "T1_BAT_BIS_11_score"] # BIS-11 is a questionnaire
imp_columns <- c(BIS_columns,"SSRT")
Patients_vs_HC_imp <- Patients_vs_HC[,c("Subject","Gruppe",imp_columns)]
## 3. Add confounds (Alter, Geschlecht, Abschluss)
Patients_vs_HC_imp_conf <- merge(Patients_vs_HC[,c("Subject","Alter","Geschlecht","Abschluss")], Patients_vs_HC_imp, by = "Subject")
# Ensure "Gruppe" is treated as a factor
Patients_vs_HC_imp$Gruppe <- as.factor(Patients_vs_HC_imp$Gruppe)
# # Function to perform Levene's test on multiple columns
# levene_test_mult_cols <- function(df_basis, cols) {
#   df <- data.frame(p_value = numeric(length(cols)))
#   rownames(df) <- cols
#
#   for (i in seq_along(cols)) {
#     col <- cols[i]
#     # Perform Levene's test, treating 'Gruppe' as a factor
#     levene_result <- car::leveneTest(df_basis[[col]] ~ df_basis[["Gruppe"]])
#     df[col, "p_value"] <- round(levene_result[1, "Pr(>F)"], 4)
#   }
#
#   return(df)
# }
# Perform Levene's test for homogeneity of variance
#levene_test_table <- levene_test_mult_cols(df_basis = Patients_vs_HC_imp, cols = imp_columns)
levene_test_table <- levene_test_mult_cols(df_basis = Patients_vs_HC_imp, cols = imp_columns, grouping_variable = "Gruppe")
pander(levene_test_table, style = "rmarkdown", fontsize = "tiny")
levene_test_table
ttest_results_columns <- c(
"group_mean_Patients", "sd_Patients",
"group_mean_HC", "sd_HC",
"df", "t_statistic", "p_value", "cohen_d", "power"
)
t_test_table <- t_test_mult_cols(df_basis = Patients_vs_HC_imp, cols = imp_columns, df_results_columns = ttest_results_columns, grouping_variable = "Gruppe")
pander(t_test_table, style = "rmarkdown", fontsize = "tiny")
t_test_table
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(tidyr)
library(pander)
library(effsize)
library(pwr)
library(gtsummary)
library(gt)
library(car)
library(flextable)
library(officer)
# User-defined functions
source("../Useful_functions.R")
format_flextable_portrait <- flextable_settings(word_orientation = "portrait")
format_flextable_landscape <- flextable_settings(word_orientation = "landscape")
basic_path = "Z:/Projekte_Meinke/Old_projects/Labrotation_Rebecca/0_Datapreparation/Daten_Gruppenvergleich/With_wrong_responses/outliers-removed"
param_suffix = basename(basic_path)
data_Pat_pre <- read.csv(file.path(basic_path,"Data_Patients_Pre.csv"))
data_Pat_pre_clean <- data_Pat_pre[!is.na(data_Pat_pre$Response),]
# Ensure "Response" is treated as a factor
data_Pat_pre_clean$Response <- as.factor(data_Pat_pre_clean$Response)
# Define the columns for which to perform the test (i.e., task performance measures)
imp_columns <- c("NumberLetter_BIS_Repeat", "NumberLetter_BIS_Switch",
"NumberLetter_BIS_Diff_Score", "Stroop_BIS_Congruent",
"Stroop_BIS_Incongruent", "Stroop_BIS_Diff_Score",
"TwoBack_BIS_Foil", "TwoBack_BIS_Target", "TwoBack_BIS_Total",
"SSRT")
#levene_test_table <- levene_test_mult_cols(df_basis = data_Pat_pre_clean, cols = imp_columns)
levene_test_table <- levene_test_mult_cols(df_basis = data_Pat_pre_clean, cols = imp_columns, grouping_variable = "Response")
pander(levene_test_table, style = "rmarkdown", fontsize = "tiny")
levene_test_table
# Run all scripts needed for the analysis sequentially
# 0. Packages and Paths
library(rmarkdown)
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Define the base path
base_path <- "Y:/PsyThera/Projekte_Meinke/Old_projects/Labrotation_Rebecca/0_Datapreparation"
parent_path <- dirname(base_path)
# 1. Taskdata_preprocessing-Skript
# Define the parameters you want to iterate over
RT_trimming_options <- c(TRUE,FALSE)
RT_remove_wrong_options <- c(TRUE,FALSE)
# Create a function to generate the filename based on parameters
generate_filename <- function(RT_trimming, RT_remove_wrong) {
trimming_text <- ifelse(RT_trimming == TRUE, "trimmed", "not_trimmed")
remove_wrong_text <- ifelse(RT_remove_wrong == TRUE, "wrong_removed", "not_removed")
#trimmed_suffix <- ifelse(RT_trimming == "TRUE", "RT_trimmed", "not_trimmed")
#wrong_suffix <- ifelse(RT_remove_wrong == "TRUE", "RT_wrong_removed", "not_removed")
#path = file.path(basic_results_path,paste(trimmed_suffix,wrong_suffix,sep = "_"),"raw_data")
paste0("Calculate_mean_RT_and_accuracy_", trimming_text,"_", remove_wrong_text, ".html")
}
# Loop over the parameter sets and render the RMarkdown file for each set
for (RT_trimming in RT_trimming_options) {
for (RT_remove_wrong in RT_remove_wrong_options){
if ((RT_trimming == TRUE && RT_remove_wrong == TRUE) ||
(RT_trimming == FALSE && RT_remove_wrong == FALSE)) {
params_list <- list(RT_trimming = RT_trimming, RT_remove_wrong =  RT_remove_wrong )
output_filename <- generate_filename(RT_trimming, RT_remove_wrong)
rmarkdown::render(
input <- file.path(base_path, "Taskdata_Preprocessing_CM - Till edit.Rmd"),
output_file = output_filename,
params = params_list,
envir = new.env()
)
cat("Generated file:", output_filename, "/n")
}
}
}
# Run all scripts needed for the analysis sequentially
# 0. Packages and Paths
library(rmarkdown)
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Define the base path
base_path <- "Y:/PsyThera/Projekte_Meinke/Old_projects/Labrotation_Rebecca/0_Datapreparation"
parent_path <- dirname(base_path)
# 1. Taskdata_preprocessing-Skript
# Define the parameters you want to iterate over
RT_trimming_options <- c(TRUE,FALSE)
RT_remove_wrong_options <- c(TRUE,FALSE)
# Create a function to generate the filename based on parameters
generate_filename <- function(RT_trimming, RT_remove_wrong) {
trimming_text <- ifelse(RT_trimming == TRUE, "trimmed", "not_trimmed")
remove_wrong_text <- ifelse(RT_remove_wrong == TRUE, "wrong_removed", "not_removed")
#trimmed_suffix <- ifelse(RT_trimming == "TRUE", "RT_trimmed", "not_trimmed")
#wrong_suffix <- ifelse(RT_remove_wrong == "TRUE", "RT_wrong_removed", "not_removed")
#path = file.path(basic_results_path,paste(trimmed_suffix,wrong_suffix,sep = "_"),"raw_data")
paste0("Calculate_mean_RT_and_accuracy_", trimming_text,"_", remove_wrong_text, ".html")
}
# Loop over the parameter sets and render the RMarkdown file for each set
for (RT_trimming in RT_trimming_options) {
for (RT_remove_wrong in RT_remove_wrong_options){
if ((RT_trimming == TRUE && RT_remove_wrong == TRUE) ||
(RT_trimming == FALSE && RT_remove_wrong == FALSE)) {
params_list <- list(RT_trimming = RT_trimming, RT_remove_wrong =  RT_remove_wrong )
output_filename <- generate_filename(RT_trimming, RT_remove_wrong)
rmarkdown::render(
input <- file.path(base_path, "Taskdata_Preprocessing_CM_TA.Rmd"),
output_file = output_filename,
params = params_list,
envir = new.env()
)
cat("Generated file:", output_filename, "/n")
}
}
}
# Run all scripts needed for the analysis sequentially
# 0. Packages and Paths
library(rmarkdown)
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Run all scripts needed for the analysis sequentially
# 0. Packages and Paths
library(rmarkdown)
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Define the base path
base_path <- "Y:/PsyThera/Projekte_Meinke/Old_projects/Labrotation_Rebecca/0_Datapreparation"
parent_path <- dirname(base_path)
# 1. Taskdata_preprocessing-Skript
# Define the parameters you want to iterate over
RT_trimming_options <- c(TRUE,FALSE)
RT_remove_wrong_options <- c(TRUE,FALSE)
# Create a function to generate the filename based on parameters
generate_filename <- function(RT_trimming, RT_remove_wrong) {
trimming_text <- ifelse(RT_trimming == TRUE, "trimmed", "not_trimmed")
remove_wrong_text <- ifelse(RT_remove_wrong == TRUE, "wrong_removed", "not_removed")
#trimmed_suffix <- ifelse(RT_trimming == "TRUE", "RT_trimmed", "not_trimmed")
#wrong_suffix <- ifelse(RT_remove_wrong == "TRUE", "RT_wrong_removed", "not_removed")
#path = file.path(basic_results_path,paste(trimmed_suffix,wrong_suffix,sep = "_"),"raw_data")
paste0("Calculate_mean_RT_and_accuracy_", trimming_text,"_", remove_wrong_text, ".html")
}
# Loop over the parameter sets and render the RMarkdown file for each set
for (RT_trimming in RT_trimming_options) {
for (RT_remove_wrong in RT_remove_wrong_options){
if ((RT_trimming == TRUE && RT_remove_wrong == TRUE) ||
(RT_trimming == FALSE && RT_remove_wrong == FALSE)) {
params_list <- list(RT_trimming = RT_trimming, RT_remove_wrong =  RT_remove_wrong )
output_filename <- generate_filename(RT_trimming, RT_remove_wrong)
rmarkdown::render(
input <- file.path(base_path, "Taskdata_Preprocessing_CM_TA.Rmd"),
output_file = output_filename,
params = params_list,
envir = new.env()
)
cat("Generated file:", output_filename, "/n")
}
}
}
# BIS-Script
outliers_removed_options <- c("yes", "no")
input_data_path_options <- c(
file.path(base_path, "Daten_Gruppenvergleich/new/RT_trimmed_RT_wrong_removed"),
file.path(base_path, "Daten_Gruppenvergleich/new/not_trimmed_not_removed")
)
# Create a function to generate the filename based on parameters
generate_filename_out <- function(outliers_removed) {
outliers_text <- ifelse(outliers_removed == "yes", "outliers-removed", "outliers-not-removed")
paste0("Calculate_BIS_", outliers_text,".html")
}
for (outliers_removed in outliers_removed_options) {
for (input_data_path in input_data_path_options){
params_list <- list(outliers_removed = outliers_removed, input_data_path = input_data_path)
output_filename <- generate_filename_out(outliers_removed)
outliers_text <- ifelse(outliers_removed == "yes", "outliers-removed", "outliers-not-removed")
output_path = file.path(input_data_path, "BIS", outliers_text, output_filename)
rmarkdown::render(
input <- file.path(base_path, "EF_scores_calculation_correct_TA.Rmd"),
output_file = output_path,
params = params_list,
envir = new.env()
)
cat("Generated file:", output_filename, "/n")
}
}
