---
title: "Calculate_permutation-based_significance"
authors: "Charlotte Meinke"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    df_print: paged
---
# Setup
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Packages
```{r}
windowsFonts(Arial=windowsFont("Arial"))
library(readr)
library(dplyr)
library(ggplot2)
```


# Load and combine results
```{r}
# Get all folders in the results folder (each containing the results of another model)
path_results_folder = "Y:\\Psythera\\Projekte_Meinke\\Old_projects\\Labrotation_Rebecca\\2_Machine_learning\\Results\\RT_trimmed_RT_wrong_removed_outliers-removed\\response_FSQ"
results_folders <- list.files(path = path_results_folder, full.names = FALSE)

# Filter for new results
results_folders_classification <- results_folders[grepl("final", results_folders)& grepl("clf", results_folders) & !grepl("permuted", results_folders)]
results_folders_regressors <- results_folders[grepl("final", results_folders)& grepl("regressor", results_folders) & !grepl("permuted", results_folders)]
```

# Permutation

## Function: Calculate p-value
```{r}
calc_p_value <- function(true_score, permuted_scores, logic = "large_better"){
  if (logic == "large_better"){
    random_better_than_true <- sum(permuted_scores > true_score)
  } else if (logic == "small_better"){
     random_better_than_true <- sum(permuted_scores < true_score)
  }
  
  #Take the following formula from scikit: https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.permutation_test_score.html#sklearn.model_selection.permutation_test_score
  p_value <- (random_better_than_true + 1)/(length(permuted_scores) +1 )
  return(p_value)
}
```

## Function: Collect and calculate p-values
```{r}
collect_p_values <- function(folders_unpermuted, evaluation_metric, logic = "large_better"){
  p_values = list()
  evaluation_metric_means = list()
  for (folder_name in folders_unpermuted) {
    
    # Initialize p_value to NA by default
    p_values[[folder_name]] <- NA
     evaluation_metric_means[[folder_name]] <- NA
    
    # Get evaluation metrics of unpermuted model
    evaluation_metrics <- read.delim(file.path(path_results_folder, folder_name, "performance_across_iters.txt"))[[evaluation_metric]]
    
    if (length(evaluation_metrics) != 100){
      print(paste("CAVE: There is an error in",folder_name))
    }
    
    # Get equivalent permuted model folder name
    folder_name_permuted <- paste0(folder_name, "_permuted")
    
    # Try to load the evaluation metric per iteration
    tryCatch({
      evaluation_metrics_permuted <- read.delim(file.path(path_results_folder, folder_name_permuted, "performance_across_iters.txt"))[[evaluation_metric]]
      
      p_values_one_folder = c()
      for (ev_metric_one_iter in evaluation_metrics){
        p_value_one_iter = calc_p_value(ev_metric_one_iter, evaluation_metrics_permuted, logic = logic)
        p_values_one_folder = c(p_values_one_folder, p_value_one_iter)
      }
      # Sum all p-values up
      p_values[[folder_name]] = mean(p_values_one_folder)
      
      }, error = function(e) {
      # Handle error and print message if permuted model is not available
      message("No permuted model available for folder: ", folder_name, " | Error: ", e$message)
      # Set p_value to NA (this is already initialized)
      p_values[[folder_name]] <- NA
      })
    # Collect true mean of evaluation metric
    evaluation_metric_means[[folder_name]] <- paste0(round(mean(evaluation_metrics),2), "(",round(sd(evaluation_metrics),2),")")
  }
  df = data.frame("models" = names(p_values), "p_values" = unlist(p_values), evaluation_metrics_means = unlist(evaluation_metric_means))
  rownames(df) <- NULL
  return(df)
}
```

# Classifiers models
```{r}
df <- collect_p_values(folders_unpermuted = results_folders_classification, evaluation_metric = "balanced_accuracy")

# Improve readibility of table
df$models <- gsub("random_forest_clf","rf",df$models)
df$models <- gsub("svm_clf","svm",df$models)
df$models <- gsub("_features","",df$models)

df
```
# Regression models
```{r}
df <- collect_p_values(folders_unpermuted = results_folders_regressors, evaluation_metric = "MSE", logic = "small_better")

df$models <- gsub("random_forest_regressopr","rf",df$models)
df$models <- gsub("ridge_regressor","ridge",df$models)
df$models <- gsub("_features","",df$models)

df
```